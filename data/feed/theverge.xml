<?xml version="1.0" encoding="UTF-8"?>
<feed xmlns="http://www.w3.org/2005/Atom" xml:lang="en">
  <title>The Verge -  All Posts</title>
  <icon>https://cdn.vox-cdn.com/community_logos/52801/VER_Logomark_32x32..png</icon>
  <updated>2024-09-25T14:40:00-04:00</updated>
  <id>https://www.theverge.com/rss/full.xml</id>
  <link type="text/html" href="https://www.theverge.com/" rel="alternate"/>
  <entry>
    <published>2024-09-25T14:40:00-04:00</published>
    <updated>2024-09-25T14:40:00-04:00</updated>
    <title>Mark Zuckerberg says there’s ‘no causal connection’ between social media and teen mental health</title>
    <content type="html">  

    &lt;figure&gt;
      &lt;img alt="Graphic collage of Mark Zuckerberg." src="https://cdn.vox-cdn.com/thumbor/cetdC7xTBkCj73cPgAlvRX70SSA=/0x0:2040x1360/1310x873/cdn.vox-cdn.com/uploads/chorus_image/image/73610212/STK169_Mark_Zuckerburg_CVIRGINIA_C.0.jpg" /&gt;
        &lt;figcaption&gt;Image: Cath Virginia / The Verge; Getty Images&lt;/figcaption&gt;
    &lt;/figure&gt;

  &lt;p id="EovcIs"&gt;Meta CEO Mark Zuckerberg is pushing back on the idea that social media directly harms teen mental health. During &lt;a href="https://www.theverge.com/e/24017522"&gt;an interview with &lt;em&gt;The Verge&lt;/em&gt;’s Alex Heath&lt;/a&gt;, Zuckerberg said that “the majority of the high-quality research out there suggests that there’s no causal connection at a broad scale between these things.”&lt;/p&gt;
&lt;p id="glwCZK"&gt;This echoes the statement Zuckerberg gave in front of Congress in January during a hearing about child safety, where he argued that existing research hasn’t shown a causal link between social media and poor teen mental health. As my colleague &lt;a href="https://www.theverge.com/policy/2024/1/31/24056884/mark-zuckerberg-is-trying-to-reset-the-conversation-on-social-medias-mental-health-effects"&gt;Adi Robertson pointed out at the time&lt;/a&gt;, it’s difficult to prove causal links, and &lt;a href="https://www.techdirt.com/2023/05/30/a-deeper-look-at-the-surgeon-generals-report-on-kids-social-media-its-not-what-you-heard/"&gt;research shows social media&lt;/a&gt; could cause both negative and positive impacts on an adolescent’s mental health.&lt;/p&gt;
&lt;div class="c-float-left c-float-hang"&gt;&lt;aside id="RNHaA8"&gt;&lt;div data-anthem-component="readmore" data-anthem-component-data='{"stories":[{"title":"Instagram is putting every teen into a more private and restrictive new account","url":"https://www.theverge.com/2024/9/17/24246423/instagram-teen-account-private-restrictive"}]}'&gt;&lt;/div&gt;&lt;/aside&gt;&lt;/div&gt;
&lt;p id="aqPzDC"&gt;“...&lt;/p&gt;
  &lt;p&gt;
    &lt;a href="https://www.theverge.com/2024/9/25/24254044/mark-zuckerberg-meta-social-media-teen-mental-health"&gt;Continue reading&amp;hellip;&lt;/a&gt;
  &lt;/p&gt;

</content>
    <link rel="alternate" type="text/html" href="https://www.theverge.com/2024/9/25/24254044/mark-zuckerberg-meta-social-media-teen-mental-health"/>
    <id>https://www.theverge.com/2024/9/25/24254044/mark-zuckerberg-meta-social-media-teen-mental-health</id>
    <author>
      <name>Emma Roth</name>
    </author>
  </entry>
  <entry>
    <published>2024-09-25T14:15:58-04:00</published>
    <updated>2024-09-25T14:15:58-04:00</updated>
    <title>The best deals you can get ahead of Amazon’s October Prime Day sale</title>
    <content type="html">  

    &lt;figure&gt;
      &lt;img alt="Amazon Echo Frames in the Carrera Cruiser model against a red backdrop" src="https://cdn.vox-cdn.com/thumbor/-0J0g5QlPPYAM0Yx8bxGtbSVK7I=/0x0:2040x1360/1310x873/cdn.vox-cdn.com/uploads/chorus_image/image/73599396/236936_Amazon_Echo_Frames_AKrales_0272.5.jpg" /&gt;
        &lt;figcaption&gt;&lt;em&gt;Amazon’s Echo Frames are a stylish pair of audio glasses that give you quick access to Amazon Alexa.&lt;/em&gt; | Photo by Amelia Holowaty Krales / The Verge&lt;/figcaption&gt;
    &lt;/figure&gt;

  &lt;p id="Ne8kSK"&gt;In case you missed the news, Amazon &lt;a href="https://www.theverge.com/2024/9/17/24244180/amazon-october-prime-day-big-deal-days-fall-dates-2024"&gt;recently announced a second Prime Day event&lt;/a&gt; for the fall. The two-day deal blitz, dubbed Prime Big Deal Days once again, will run from October 8th through the 9th, offering Prime subscribers a chance to save on all sorts of tech ahead of Black Friday. It’s still a couple of weeks away, but in typical fashion, Amazon has already rolled out a selection of early deals and discounts.&lt;/p&gt;
&lt;div class="c-float-left c-float-hang"&gt;&lt;aside id="8WJBYA"&gt;&lt;div data-anthem-component="readmore" data-anthem-component-data='{"stories":[{"title":"Know the price-matching policies for Best Buy, Target, Walmart, and others","url":"https://www.theverge.com/21570383/price-matching-policy-apple-google-microsoft"},{"title":"It looks like Walmart is holding a rival Prime Day event in the fall","url":"https://www.theverge.com/2024/9/19/24249418/walmarts-holding-a-rival-fall-prime-day-event"},{"title":"How to find the best deals during Amazon’s fall Prime Day sale","url":"https://www.theverge.com/21502865/amazon-prime-day-best-deals-how-to-find"}]}'&gt;&lt;/div&gt;&lt;/aside&gt;&lt;/div&gt;
&lt;p id="da5RpW"&gt;Admittedly, there aren’t &lt;em&gt;that&lt;/em&gt; many gadgets on sale yet — and we’ll likely start to see better deals trickle in as we get closer to the event — but we’ve still managed to dig up a few solid deals, particularly for those already embedded in the Amazon ecosystem. These include sizable discounts on &lt;a href="https://www.amazon.com/dp/B0BL5RKSHH/?tag=theverge02-20" rel="sponsored nofollow noopener" target="_blank"&gt;Amazon’s Echo Frames&lt;/a&gt;, as well...&lt;/p&gt;
  &lt;p&gt;
    &lt;a href="https://www.theverge.com/24248182/amazon-october-prime-day-best-early-deals-echo-speakers-displays-fire-tablets-sale"&gt;Continue reading&amp;hellip;&lt;/a&gt;
  &lt;/p&gt;

</content>
    <link rel="alternate" type="text/html" href="https://www.theverge.com/24248182/amazon-october-prime-day-best-early-deals-echo-speakers-displays-fire-tablets-sale"/>
    <id>https://www.theverge.com/24248182/amazon-october-prime-day-best-early-deals-echo-speakers-displays-fire-tablets-sale</id>
    <author>
      <name>Sheena Vasani</name>
    </author>
  </entry>
  <entry>
    <published>2024-09-25T14:15:00-04:00</published>
    <updated>2024-09-25T14:15:00-04:00</updated>
    <title>Mark Zuckerberg: creators and publishers ‘overestimate the value’ of their work for training AI</title>
    <content type="html">  

    &lt;figure&gt;
      &lt;img alt="Graphic collage of Mark Zuckerberg." src="https://cdn.vox-cdn.com/thumbor/8BTKgEgKvnwhrlQSNCWAQMYZE9k=/0x0:2040x1360/1310x873/cdn.vox-cdn.com/uploads/chorus_image/image/73610132/STK169_Mark_Zuckerburg_CVIRGINIA_D.0.jpg" /&gt;
        &lt;figcaption&gt;Image: Cath Virginia / The Verge; Getty Images&lt;/figcaption&gt;
    &lt;/figure&gt;

  &lt;p id="nUj4m7"&gt;Meta CEO Mark Zuckerberg says there are complex copyright questions around scraping data to train AI models, but he suggests the individual work of most creators isn’t valuable enough for it to matter. In an interview with &lt;em&gt;The Verge&lt;/em&gt; deputy editor Alex Heath, Zuckerberg said Meta will likely strike “certain partnerships” for useful content. But if others demand payment, then — as it’s &lt;a href="https://www.theverge.com/2023/8/1/23815994/meta-facebook-instagram-canada-news-act-blocking"&gt;done with news outlets&lt;/a&gt; — the company would prefer to walk away.&lt;/p&gt;
&lt;p id="mOO9Sq"&gt;“I think individual creators or publishers tend to overestimate the value of their specific content in the grand scheme of this,” Zuckerberg said &lt;a href="https://www.theverge.com/e/24017522"&gt;in the interview&lt;/a&gt;, which coincides with Meta’s annual Connect event. “My guess is that there are going to be certain partnerships that get made when...&lt;/p&gt;
  &lt;p&gt;
    &lt;a href="https://www.theverge.com/2024/9/25/24254042/mark-zuckerberg-creators-value-ai-meta"&gt;Continue reading&amp;hellip;&lt;/a&gt;
  &lt;/p&gt;

</content>
    <link rel="alternate" type="text/html" href="https://www.theverge.com/2024/9/25/24254042/mark-zuckerberg-creators-value-ai-meta"/>
    <id>https://www.theverge.com/2024/9/25/24254042/mark-zuckerberg-creators-value-ai-meta</id>
    <author>
      <name>Adi Robertson</name>
    </author>
  </entry>
  <entry>
    <published>2024-09-25T14:13:29-04:00</published>
    <updated>2024-09-25T14:13:29-04:00</updated>
    <title>Meta is working on recreating influencers with AI</title>
    <content type="html">  

    &lt;figure&gt;
      &lt;img alt="Mark Zuckerberg presenting the Reels translation feature at Connect 2024." src="https://cdn.vox-cdn.com/thumbor/rEhnAAdossoNAWtylsmUTkxOm7g=/45x0:4016x2647/1310x873/cdn.vox-cdn.com/uploads/chorus_image/image/73610130/IMG_5583.0.jpg" /&gt;
        &lt;figcaption&gt;Photo by Jay Peters / The Verge&lt;/figcaption&gt;
    &lt;/figure&gt;

  &lt;p id="0eMYrJ"&gt;Meta has big ambitions for using AI to help creators, and it showed two impressive demos of what that could look like onstage at Connect today.&lt;/p&gt;
&lt;p id="SMSqeR"&gt;One version of this involves fully recreating real influencers as AI figures. Meta CEO Mark Zuckerberg presented a live demo of a creator-based AI persona, which looked like the creator, talked like the creator, and tried to respond to questions like the creator would. &lt;a href="https://www.instagram.com/reel/DAWYFfuPqu9/"&gt;It was pretty wild to watch&lt;/a&gt;. &lt;/p&gt;
&lt;div id="0IHqgy"&gt;
&lt;blockquote class="instagram-media" data-instgrm-captioned="" data-instgrm-permalink="https://www.instagram.com/reel/DAWYFfuPqu9/?utm_source=ig_embed&amp;amp;utm_campaign=loading" data-instgrm-version="14" style=" background:#FFF; border:0; border-radius:3px; box-shadow:0 0 1px 0 rgba(0,0,0,0.5),0 1px 10px 0 rgba(0,0,0,0.15); margin: 1px; max-width:658px; min-width:326px; padding:0; width:99.375%; width:-webkit-calc(100% - 2px); width:calc(100% - 2px);"&gt;&lt;div style="padding:16px;"&gt; &lt;a href="https://www.instagram.com/reel/DAWYFfuPqu9/?utm_source=ig_embed&amp;amp;utm_campaign=loading" style=" background:#FFFFFF; line-height:0; padding:0 0; text-align:center; text-decoration:none; width:100%;" target="_blank"&gt; &lt;div style=" display: flex; flex-direction: row; align-items: center;"&gt; &lt;div style="background-color: #F4F4F4; border-radius: 50%; flex-grow: 0; height: 40px; margin-right: 14px; width: 40px;"&gt;&lt;/div&gt; &lt;div style="display: flex; flex-direction: column; flex-grow: 1; justify-content: center;"&gt; &lt;div style=" background-color: #F4F4F4; border-radius: 4px; flex-grow: 0; height: 14px; margin-bottom: 6px; width: 100px;"&gt;&lt;/div&gt; &lt;div style=" background-color: #F4F4F4; border-radius: 4px; flex-grow: 0; height: 14px; width: 60px;"&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div style="padding: 19% 0;"&gt;&lt;/div&gt; &lt;div style="display:block; height:50px; margin:0 auto 12px; width:50px;"&gt;&lt;svg width="50px" height="50px" viewbox="0 0 60 60" version="1.1" xmlns="https://www.w3.org/2000/svg" xmlns:xlink="https://www.w3.org/1999/xlink"&gt;&lt;g stroke="none" stroke-width="1" fill="none" fill-rule="evenodd"&gt;&lt;g transform="translate(-511.000000, -20.000000)" fill="#000000"&gt;&lt;g&gt;&lt;path d="M556.869,30.41 C554.814,30.41 553.148,32.076 553.148,34.131 C553.148,36.186 554.814,37.852 556.869,37.852 C558.924,37.852 560.59,36.186 560.59,34.131 C560.59,32.076 558.924,30.41 556.869,30.41 M541,60.657 C535.114,60.657 530.342,55.887 530.342,50 C530.342,44.114 535.114,39.342 541,39.342 C546.887,39.342 551.658,44.114 551.658,50 C551.658,55.887 546.887,60.657 541,60.657 M541,33.886 C532.1,33.886 524.886,41.1 524.886,50 C524.886,58.899 532.1,66.113 541,66.113 C549.9,66.113 557.115,58.899 557.115,50 C557.115,41.1 549.9,33.886 541,33.886 M565.378,62.101 C565.244,65.022 564.756,66.606 564.346,67.663 C563.803,69.06 563.154,70.057 562.106,71.106 C561.058,72.155 560.06,72.803 558.662,73.347 C557.607,73.757 556.021,74.244 553.102,74.378 C549.944,74.521 548.997,74.552 541,74.552 C533.003,74.552 532.056,74.521 528.898,74.378 C525.979,74.244 524.393,73.757 523.338,73.347 C521.94,72.803 520.942,72.155 519.894,71.106 C518.846,70.057 518.197,69.06 517.654,67.663 C517.244,66.606 516.755,65.022 516.623,62.101 C516.479,58.943 516.448,57.996 516.448,50 C516.448,42.003 516.479,41.056 516.623,37.899 C516.755,34.978 517.244,33.391 517.654,32.338 C518.197,30.938 518.846,29.942 519.894,28.894 C520.942,27.846 521.94,27.196 523.338,26.654 C524.393,26.244 525.979,25.756 528.898,25.623 C532.057,25.479 533.004,25.448 541,25.448 C548.997,25.448 549.943,25.479 553.102,25.623 C556.021,25.756 557.607,26.244 558.662,26.654 C560.06,27.196 561.058,27.846 562.106,28.894 C563.154,29.942 563.803,30.938 564.346,32.338 C564.756,33.391 565.244,34.978 565.378,37.899 C565.522,41.056 565.552,42.003 565.552,50 C565.552,57.996 565.522,58.943 565.378,62.101 M570.82,37.631 C570.674,34.438 570.167,32.258 569.425,30.349 C568.659,28.377 567.633,26.702 565.965,25.035 C564.297,23.368 562.623,22.342 560.652,21.575 C558.743,20.834 556.562,20.326 553.369,20.18 C550.169,20.033 549.148,20 541,20 C532.853,20 531.831,20.033 528.631,20.18 C525.438,20.326 523.257,20.834 521.349,21.575 C519.376,22.342 517.703,23.368 516.035,25.035 C514.368,26.702 513.342,28.377 512.574,30.349 C511.834,32.258 511.326,34.438 511.181,37.631 C511.035,40.831 511,41.851 511,50 C511,58.147 511.035,59.17 511.181,62.369 C511.326,65.562 511.834,67.743 512.574,69.651 C513.342,71.625 514.368,73.296 516.035,74.965 C517.703,76.634 519.376,77.658 521.349,78.425 C523.257,79.167 525.438,79.673 528.631,79.82 C531.831,79.965 532.853,80.001 541,80.001 C549.148,80.001 550.169,79.965 553.369,79.82 C556.562,79.673 558.743,79.167 560.652,78.425 C562.623,77.658 564.297,76.634 565.965,74.965 C567.633,73.296 568.659,71.625 569.425,69.651 C570.167,67.743 570.674,65.562 570.82,62.369 C570.966,59.17 571,58.147 571,50 C571,41.851 570.966,40.831 570.82,37.631"&gt;&lt;/path&gt;&lt;/g&gt;&lt;/g&gt;&lt;/g&gt;&lt;/svg&gt;&lt;/div&gt;
&lt;div style="padding-top: 8px;"&gt; &lt;div style=" color:#3897f0; font-family:Arial,sans-serif; font-size:14px; font-style:normal; font-weight:550; line-height:18px;"&gt;View this post on Instagram&lt;/div&gt;
&lt;/div&gt;
&lt;div style="padding: 12.5% 0;"&gt;&lt;/div&gt; &lt;div style="display: flex; flex-direction: row; margin-bottom: 14px; align-items: center;"&gt;
&lt;div&gt; &lt;div style="background-color: #F4F4F4; border-radius: 50%; height: 12.5px; width: 12.5px; transform: translateX(0px) translateY(7px);"&gt;&lt;/div&gt; &lt;div style="background-color: #F4F4F4; height: 12.5px; transform: rotate(-45deg) translateX(3px) translateY(1px); width: 12.5px; flex-grow: 0; margin-right: 14px; margin-left: 2px;"&gt;&lt;/div&gt; &lt;div style="background-color: #F4F4F4; border-radius: 50%; height: 12.5px; width: 12.5px; transform: translateX(9px) translateY(-18px);"&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;div style="margin-left: 8px;"&gt; &lt;div style=" background-color: #F4F4F4; border-radius: 50%; flex-grow: 0; height: 20px; width: 20px;"&gt;&lt;/div&gt; &lt;div style=" width: 0; height: 0; border-top: 2px solid transparent; border-left: 6px solid #f4f4f4; border-bottom: 2px solid transparent; transform: translateX(16px) translateY(-4px) rotate(30deg)"&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;div style="margin-left: auto;"&gt; &lt;div style=" width: 0px; border-top: 8px solid #F4F4F4; border-right: 8px solid transparent; transform: translateY(16px);"&gt;&lt;/div&gt; &lt;div style=" background-color: #F4F4F4; flex-grow: 0; height: 12px; width: 16px; transform: translateY(-4px);"&gt;&lt;/div&gt; &lt;div style=" width: 0; height: 0; border-top: 8px solid #F4F4F4; border-left: 8px solid transparent; transform: translateY(-4px) translateX(8px);"&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt; &lt;div style="display: flex; flex-direction: column; flex-grow: 1; justify-content: center; margin-bottom: 24px;"&gt; &lt;div style=" background-color: #F4F4F4; border-radius: 4px; flex-grow: 0; height: 14px; margin-bottom: 6px; width: 224px;"&gt;&lt;/div&gt; &lt;div style=" background-color: #F4F4F4; border-radius: 4px; flex-grow: 0; height: 14px; width: 144px;"&gt;&lt;/div&gt;
&lt;/div&gt;&lt;/a&gt;&lt;p style=" color:#c9c8cd; font-family:Arial,sans-serif; font-size:14px; line-height:17px; margin-bottom:0; margin-top:8px; overflow:hidden; padding:8px 0 7px; text-align:center; text-overflow:ellipsis; white-space:nowrap;"&gt;&lt;a href="https://www.instagram.com/reel/DAWYFfuPqu9/?utm_source=ig_embed&amp;amp;utm_campaign=loading" style=" color:#c9c8cd; font-family:Arial,sans-serif; font-size:14px; font-style:normal; font-weight:normal; line-height:17px; text-decoration:none;" target="_blank"&gt;A post shared by The Verge (@verge)&lt;/a&gt;&lt;/p&gt;
&lt;/div&gt;&lt;/blockquote&gt;

&lt;/div&gt;
&lt;p id="iWqJfV"&gt;Another tool it’s developing takes Reels and automatically dubs them into another language, maintaining the creator’s voice and even changing the movements of their mouth to match. &lt;/p&gt;
&lt;p id="rGWg7Q"&gt;Zuckerberg presented...&lt;/p&gt;
  &lt;p&gt;
    &lt;a href="https://www.theverge.com/2024/9/25/24254190/meta-connect-2024-ai-auto-dubbing-lip-syncing"&gt;Continue reading&amp;hellip;&lt;/a&gt;
  &lt;/p&gt;

</content>
    <link rel="alternate" type="text/html" href="https://www.theverge.com/2024/9/25/24254190/meta-connect-2024-ai-auto-dubbing-lip-syncing"/>
    <id>https://www.theverge.com/2024/9/25/24254190/meta-connect-2024-ai-auto-dubbing-lip-syncing</id>
    <author>
      <name>Jay Peters</name>
    </author>
  </entry>
  <entry>
    <published>2024-09-25T14:09:32-04:00</published>
    <updated>2024-09-25T14:09:32-04:00</updated>
    <title>Everything announced at Meta Connect 2024</title>
    <content type="html">  

    &lt;figure&gt;
      &lt;img alt="A person holding a Quest 3S." src="https://cdn.vox-cdn.com/thumbor/ItbmLtvxAOHZLKLFmsXVPc8NVUE=/0x0:2700x1800/1310x873/cdn.vox-cdn.com/uploads/chorus_image/image/73610126/247283_Quest_3S_VPavic_0059.0.jpg" /&gt;
        &lt;figcaption&gt;Photo by Vjeran Pavic / The Verge&lt;/figcaption&gt;
    &lt;/figure&gt;

  &lt;p id="OlCRBL"&gt;Meta has a bunch of new hardware and AI news coming out of its Meta Connect event today, including a new Quest 3S VR headset, an expansion of Meta AI features, a new Llama model, and a first look at the new Orion augmented reality glasses. CEO Mark Zuckerberg took the stage on Wednesday &lt;a href="https://www.theverge.com/2024/9/25/24254262/zuck-or-nothing"&gt;with a new style&lt;/a&gt; and demonstrated new features including live translation between English and Spanish.&lt;/p&gt;
&lt;p id="9gcQ6x"&gt;Here’s everything announced at Meta Connect:&lt;/p&gt;
&lt;h2 id="DfbeEz"&gt;&lt;a href="https://www.theverge.com/e/24017949"&gt;Orion AR glasses&lt;/a&gt;&lt;/h2&gt;
&lt;figure class="e-image"&gt;
        
      &lt;cite&gt;Photo by Vjeran Pavic / The Verge&lt;/cite&gt;
  &lt;/figure&gt;
&lt;p id="eX8FYB"&gt;Meta has revealed its Orion augmented reality glasses, and they look almost like a trendy pair of frames you could pick up without all the tech inside. Orion uses Micro LED projectors inside the frame and beams images in front of your eyes...&lt;/p&gt;
  &lt;p&gt;
    &lt;a href="https://www.theverge.com/24254101/meta-connect-2024-announcements-products"&gt;Continue reading&amp;hellip;&lt;/a&gt;
  &lt;/p&gt;

</content>
    <link rel="alternate" type="text/html" href="https://www.theverge.com/24254101/meta-connect-2024-announcements-products"/>
    <id>https://www.theverge.com/24254101/meta-connect-2024-announcements-products</id>
    <author>
      <name>Umar Shakir</name>
    </author>
  </entry>
  <entry>
    <published>2024-09-25T13:50:56-04:00</published>
    <updated>2024-09-25T13:50:56-04:00</updated>
    <title>Why Mark Zuckerberg thinks AR glasses will replace your phone</title>
    <content type="html">  

    &lt;figure&gt;
      &lt;img alt="A photo illustration of Meta CEO Mark Zuckerberg" src="https://cdn.vox-cdn.com/thumbor/6JmctVka5aQFHoU3xkhQTnO6meY=/0x0:2040x1360/1310x873/cdn.vox-cdn.com/uploads/chorus_image/image/73610047/DCD_Zuckerberg_2024.0.jpg" /&gt;
        &lt;figcaption&gt;Photo by Vjeran Pavic / The Verge&lt;/figcaption&gt;
    &lt;/figure&gt;


  		 &lt;p&gt;Meta’s CEO on his first pair of AR glasses, partnering with Ray-Ban, why he’s done with politics, and more.&lt;/p&gt;
  &lt;p&gt;
    &lt;a href="https://www.theverge.com/24253481/meta-ceo-mark-zuckerberg-ar-glasses-orion-ray-bans-ai-decoder-interview"&gt;Continue reading&amp;hellip;&lt;/a&gt;
  &lt;/p&gt;

</content>
    <link rel="alternate" type="text/html" href="https://www.theverge.com/24253481/meta-ceo-mark-zuckerberg-ar-glasses-orion-ray-bans-ai-decoder-interview"/>
    <id>https://www.theverge.com/24253481/meta-ceo-mark-zuckerberg-ar-glasses-orion-ray-bans-ai-decoder-interview</id>
    <author>
      <name>Nilay Patel</name>
      <name>Alex Heath</name>
    </author>
  </entry>
  <entry>
    <published>2024-09-25T13:50:09-04:00</published>
    <updated>2024-09-25T13:50:09-04:00</updated>
    <title>Hands-on with Orion, Meta’s first pair of AR glasses</title>
    <content type="html">  

    &lt;figure&gt;
      &lt;img alt="A person wearing a pair of Orion smart glasses facing the camera" src="https://cdn.vox-cdn.com/thumbor/h8bUpJoBwQJyI6hMqwBlG2BdiEo=/0x0:2700x1800/1310x873/cdn.vox-cdn.com/uploads/chorus_image/image/73610042/247284_Project_Orion_VPavic_0101.0.jpg" /&gt;
    &lt;/figure&gt;


  		 &lt;p&gt;Orion is an impressive demo of AR glasses, but can Mark Zuckerberg beat everyone else to the next big platform?&lt;/p&gt;
  &lt;p&gt;
    &lt;a href="https://www.theverge.com/24253908/meta-orion-ar-glasses-demo-mark-zuckerberg-interview"&gt;Continue reading&amp;hellip;&lt;/a&gt;
  &lt;/p&gt;

</content>
    <link rel="alternate" type="text/html" href="https://www.theverge.com/24253908/meta-orion-ar-glasses-demo-mark-zuckerberg-interview"/>
    <id>https://www.theverge.com/24253908/meta-orion-ar-glasses-demo-mark-zuckerberg-interview</id>
    <author>
      <name>Alex Heath</name>
    </author>
  </entry>
  <entry>
    <published>2024-09-25T13:38:49-04:00</published>
    <updated>2024-09-25T13:38:49-04:00</updated>
    <title>Meta’s Ray-Bans will now ‘remember’ things for you</title>
    <content type="html">  

    &lt;figure&gt;
      &lt;img alt="Meta’s new Ray-Ban Meta clear frames" src="https://cdn.vox-cdn.com/thumbor/j_ac4Ur441YarOyLVL7gmk7i37Q=/0x0:2700x1800/1310x873/cdn.vox-cdn.com/uploads/chorus_image/image/73610000/247282_Meta_Ray_Ban_ltd_edition_VPavic_0042.0.jpg" /&gt;
        &lt;figcaption&gt;Photo by Vjeran Pavic / The Verge&lt;/figcaption&gt;
    &lt;/figure&gt;

  &lt;p id="QU0woH"&gt;Meta’s Ray-Ban smart glasses are already &lt;a href="https://www.theverge.com/2024/4/23/24138090/ray-ban-meta-smart-glasses-ai-wearables"&gt;one of the best cracks at AI hardware&lt;/a&gt; to date. Now, Meta is pushing out a series of software updates, along with a new translucent Ray-Ban style, that bring the smart glasses closer to actually &lt;em&gt;feeling&lt;/em&gt; smart.&lt;/p&gt;
&lt;p id="Zh4zPM"&gt;The company announced several updates to the Ray-Ban Meta glasses at its Connect conference on Wednesday, introducing new features like “Reminders,” which has the glasses take a photo of what you’re looking at and remind you about it later through a notification on your phone. You’ll also be able to scan QR codes and call phone numbers you’re looking at directly from the glasses. &lt;/p&gt;
&lt;p id="DeA9XE"&gt;The Meta Ray-Bans can already translate a handful of languages from still images. Now, the company says it’s...&lt;/p&gt;
  &lt;p&gt;
    &lt;a href="https://www.theverge.com/2024/9/25/24253712/meta-rayban-ai-features-reminders-translation-transparent-style"&gt;Continue reading&amp;hellip;&lt;/a&gt;
  &lt;/p&gt;

</content>
    <link rel="alternate" type="text/html" href="https://www.theverge.com/2024/9/25/24253712/meta-rayban-ai-features-reminders-translation-transparent-style"/>
    <id>https://www.theverge.com/2024/9/25/24253712/meta-rayban-ai-features-reminders-translation-transparent-style</id>
    <author>
      <name>Kylie Robison</name>
    </author>
  </entry>
  <entry>
    <published>2024-09-25T13:29:35-04:00</published>
    <updated>2024-09-25T13:29:35-04:00</updated>
    <title>VR artists can now buy Logitech’s pen-shaped Meta Quest controller</title>
    <content type="html">  

    &lt;figure&gt;
      &lt;img alt="A person’s hand holding the Logitech MC Ink stylus for the Meta Quest." src="https://cdn.vox-cdn.com/thumbor/3yO-dX8ieKrJfnZLSPAl5n7eYrs=/211x0:3066x1903/1310x873/cdn.vox-cdn.com/uploads/chorus_image/image/73609959/Logitech_MX_Ink_stylus.0.jpg" /&gt;
        &lt;figcaption&gt;&lt;em&gt;The MX Ink is available to buy now following its announcement back in June.&lt;/em&gt; | Image: Logitech&lt;/figcaption&gt;
    &lt;/figure&gt;

  &lt;p id="XidbGM"&gt;Logitech has released &lt;a href="https://logitech.cfzu.net/c/482924/2154947/11355?subId1=verge092524"&gt;a pen-shaped Meta Quest controller&lt;/a&gt; that makes it easier to draw, sculpt, and manipulate objects in mixed reality environments. After &lt;a href="https://www.theverge.com/2024/6/17/24180060/logitech-mx-ink-stylus-meta-quest-vr-ar"&gt;initially being announced back in June&lt;/a&gt;, the $129.99 Logitech MX Ink stylus is available to buy starting today and can be paired with the Meta Quest 3S, Quest 3, and Quest 2 headsets via the Meta Quest app.&lt;/p&gt;
&lt;p id="o0g3gy"&gt;The MX Ink should feel more comfortable and natural to use across 2D and 3D creative software compared to much bulkier Quest controllers, especially for artists who are more accustomed to working on traditional drawing tablets. It’ll be down to developers to make their apps compatible with the stylus, with support already announced for &lt;a href="https://www.youtube.com/shorts/4gg8Ve0sGxE"&gt;Open Brush&lt;/a&gt;, Gravity Sketch, and Adobe Substance...&lt;/p&gt;
  &lt;p&gt;
    &lt;a href="https://www.theverge.com/2024/9/25/24254218/logitech-mx-ink-meta-quest-stylus-controller-availability"&gt;Continue reading&amp;hellip;&lt;/a&gt;
  &lt;/p&gt;

</content>
    <link rel="alternate" type="text/html" href="https://www.theverge.com/2024/9/25/24254218/logitech-mx-ink-meta-quest-stylus-controller-availability"/>
    <id>https://www.theverge.com/2024/9/25/24254218/logitech-mx-ink-meta-quest-stylus-controller-availability</id>
    <author>
      <name>Jess Weatherbed</name>
    </author>
  </entry>
  <entry>
    <published>2024-09-25T13:28:46-04:00</published>
    <updated>2024-09-25T13:28:46-04:00</updated>
    <title>Meta’s AI can now talk to you in the voices of Awkwafina, John Cena, and Judi Dench</title>
    <content type="html">  

    &lt;figure&gt;
      &lt;img alt="Image of Meta’s logo with a red and blue background." src="https://cdn.vox-cdn.com/thumbor/US1RC-ksQbpsxcfqwpUU5IJFsow=/0x0:2040x1360/1310x873/cdn.vox-cdn.com/uploads/chorus_image/image/73609950/STK043_VRG_Illo_N_Barclay_1_Meta.0.jpg" /&gt;
        &lt;figcaption&gt;Illustration by Nick Barclay / The Verge&lt;/figcaption&gt;
    &lt;/figure&gt;

  &lt;p id="OcEc4N"&gt;Meta is adding conversational voices by celebrities to its AI chatbot in Instagram, WhatsApp, and Facebook. &lt;/p&gt;
&lt;p id="SxlkrZ"&gt;The company &lt;a href="https://about.fb.com/news/2024/09/metas-ai-product-news-connect/"&gt;announced&lt;/a&gt; at its Connect event today that you can now talk to Meta AI and hear it respond in one of several voices, including celebrity soundalikes such as Awkwafina, John Cena, Keegan-Michael Key, Kristen Bell, and the only one I truly care about: Dame Judi Dench.&lt;/p&gt;
&lt;div id="5bLIUo"&gt;
&lt;!--  ########  BEGIN VOLUME VIDEO  ########  --&gt;&lt;div data-analytics-viewport="video" data-analytics-action="volume:view:article:middle" data-analytics-label="Meta AI Voices, ft. Judi Dench, Keegan-Michael Key, Kristen Bell|117916" data-volume-uuid="db08bdb88" data-volume-id="117916" data-analytics-placement="article:middle" data-volume-placement="article" data-volume-autoplay="false" id="volume-placement-298" class="volume-video"&gt;&lt;/div&gt;
&lt;!--  ########  END VOLUME VIDEO  ########  --&gt;&lt;div class="caption"&gt;&lt;em&gt;Meta’s AI voices, ft. Judi Dench, Keegan-Michael Key, Kristen Bell&lt;/em&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;p id="SAE4gO"&gt;These celebrity voices will only be available to US users of Meta’s apps to start. And if you prefer a voice that is a little more mundane, you can also pick from non-celeb voices with names like “Aspen,” “Atlas,” or “Clover.” &lt;a href="https://www.theverge.com/2024/8/13/24219553/google-gemini-live-voice-chat-mode"&gt;Google&lt;/a&gt; and &lt;a href="https://www.theverge.com/2024/8/15/24220378/openai-advanced-voice-mode-uncanny-valley"&gt;OpenAI&lt;/a&gt; also now offer similar conversational...&lt;/p&gt;
  &lt;p&gt;
    &lt;a href="https://www.theverge.com/2024/9/25/24253420/meta-ai-celebrity-voices-awkwafina-john-cena-judi-dench-connect"&gt;Continue reading&amp;hellip;&lt;/a&gt;
  &lt;/p&gt;

</content>
    <link rel="alternate" type="text/html" href="https://www.theverge.com/2024/9/25/24253420/meta-ai-celebrity-voices-awkwafina-john-cena-judi-dench-connect"/>
    <id>https://www.theverge.com/2024/9/25/24253420/meta-ai-celebrity-voices-awkwafina-john-cena-judi-dench-connect</id>
    <author>
      <name>Wes Davis</name>
    </author>
  </entry>
</feed>
