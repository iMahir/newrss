[
  {
    "title": "Biden administration raises tariffs on solar materials from China ",
    "link": "https://www.theverge.com/2024/12/12/24319521/china-tariffs-solar-energy-wafer-polysilicon-tungsten",
    "pubDate": "2024-12-12T16:46:18.000Z",
    "content": "  \n\n    <figure>\n      <img alt=\"A worker wearing a mask, a white garb and gloves grasps a slab of material in a factory.\" src=\"https://cdn.vox-cdn.com/thumbor/BG-xKa_FQhySW6vbNj-WNnR_PYg=/0x3:3373x2252/1310x873/cdn.vox-cdn.com/uploads/chorus_image/image/73782734/2161788194.0.jpg\" />\n        <figcaption>A worker handles wafers at the GCL Technology production plant in Xuzhou, Jiangsu Province, China, on Tuesday, July 2, 2024. GCL Technology is one of the world’s largest makers of polysilicon, a key material in solar panels. | Photo: Getty Images</figcaption>\n    </figure>\n\n  <p id=\"PyRUpE\">Tariffs on solar wafers, polysilicon, and certain tungsten products from China are going to rise dramatically come January 1st, 2025, the Biden administration announced Wednesday. That means higher price tags on key materials needed to make solar panels at a time when solar is the <a href=\"https://emp.lbl.gov/sites/default/files/2024-04/Queued%20Up%202024%20Edition_1.pdf\">fastest growing source</a> of electricity in the US. </p>\n<p id=\"iz3Jsh\">Polysilicon is used to make solar wafers, which are the semiconductors in solar panels. Tungsten — the same material in old-school incandescent lightbulbs — has many uses in electronics because of its high melting point. The metal is also part of supply chains for the aerospace, automotive, defense, medical, and oil and gas industries.</p>\n<div class=\"c-float-left c-float-hang\"><aside id=\"WMMSN2\"><q>That means higher price tags on key materials needed to make solar panels at a time when solar is the fastest growing source of electricity in the US</q></aside></div>\n<p id=\"4aXLjy\">It’s the latest instance of the Biden administration hiking up tariffs on goods from China — which dominates solar manufacturing — as part of its plan to build up domestic supply chains for clean energy. </p>\n<p id=\"uKwvsm\">Solar products from the Xinjiang region in particular also face <a href=\"https://www.business-humanrights.org/en/latest-news/china-solar-companies-linked-to-forced-labour-allegations/\">accusations of forced labor and human rights abuses</a>. The Office of the US Trade Representative (USTR) also said that the decision to raise tariffs follows an investigation into <a href=\"https://ustr.gov/sites/default/files/05.14.2024%20Four%20Year%20Review%20of%20China%20Tech%20Transfer%20Section%20301%20(Final).pdf\">cyber theft and economic espionage</a> by China.</p>\n<p id=\"X0rmDV\">“The tariff increases announced today will further blunt the harmful policies and practices by the People’s Republic of China,” ambassador Katherine Tai said in a <a href=\"https://ustr.gov/about-us/policy-offices/press-office/press-releases/2024/december/ustr-increases-tariffs-under-section-301-tungsten-products-wafers-and-polysilicon-concluding\">statement</a>. “These actions will complement the domestic investments made under the Biden-Harris Administration to promote a clean energy economy, while increasing the resilience of critical supply chains.”</p>\n<p id=\"zziJ1A\">Starting next year, tariffs on polysilicon and solar wafers will <a href=\"https://apnews.com/article/china-us-tariffs-tungsten-solar-a9653d4b14051d78314c2bd8111510e7\">double</a> from 25 to 50 percent. Tariffs on certain tungsten products will go <a href=\"https://apnews.com/article/china-us-tariffs-tungsten-solar-a9653d4b14051d78314c2bd8111510e7\">from zero</a> to 25 percent. Chinese companies <a href=\"https://cen.acs.org/energy/solar-power/US-solar-polysilicon-supply-problem/100/i33\">produce more than 75 percent of the world’s polysilicon</a>. Considering all the <a href=\"https://www.iea.org/reports/solar-pv-global-supply-chains/executive-summary\">manufacturing stages for solar panels</a>, which includes polysilicon and wafers, China holds <a href=\"https://www.woodmac.com/press-releases/china-dominance-on-global-solar-supply-chain/\">more than 80 percent</a> of global capacity.</p>\n<p id=\"m7plug\">American manufacturers welcomed the changes. “These trade measures will begin to counter the pervasive Chinese government subsidies in solar manufacturing. It is a step in the right direction,” Mike Carr, executive director of the Solar Energy Manufacturers for America (SEMA) Coalition, said in an emailed statement. </p>\n<div class=\"c-float-left c-float-hang\"><aside id=\"LdhoQk\"><div data-anthem-component=\"readmore\" data-anthem-component-data='{\"stories\":[{\"title\":\"What does Trump’s election mean for EVs, Tesla, and Elon Musk? \",\"url\":\"https://www.theverge.com/2024/11/6/24289494/trump-election-electric-vehicle-tax-credit-tesla-elon-musk\"},{\"title\":\"What a second Trump presidency means for tech \",\"url\":\"https://www.theverge.com/2024/11/8/24291333/second-trump-tech-policy-antitrust-ai-crypto\"},{\"title\":\"US to raise tariffs on EVs, batteries, solar cells, and computer chips from China \",\"url\":\"https://www.theverge.com/2024/5/14/24156249/us-biden-china-tariffs-ev-solar-battery-semiconductor-critical-minerals\"}]}'></div></aside></div>\n<p id=\"KyVtcs\">To be sure, Chinese policies aimed at boosting solar manufacturing have led to economies of scale that have <a href=\"https://www.iea.org/reports/solar-pv-global-supply-chains/executive-summary\">allowed prices for solar panels to plummet around the world</a>. Chinese companies also make much <a href=\"https://www.theverge.com/2024/5/10/24153830/biden-china-ev-tariff-quadruple-trade\">more affordable electric vehicles</a> than US manufacturers. EVs from China have been similarly subject to <a href=\"https://www.theverge.com/2024/5/14/24156249/us-biden-china-tariffs-ev-solar-battery-semiconductor-critical-minerals\">soaring tariffs during the Biden administration</a> to 100 percent from 25 percent this year. In May, Biden also <a href=\"https://www.whitehouse.gov/briefing-room/statements-releases/2024/05/14/fact-sheet-president-biden-takes-action-to-protect-american-workers-and-businesses-from-chinas-unfair-trade-practices/\">announced</a> that tariffs on battery parts and lithium-ion batteries would rise to 25 percent from 7.5 percent. In addition, he increased the tarifff rate on solar cells from 25 percent to 50 percent. And by 2025, the rate on semiconductors from China will double to 50 percent.</p>\n<p id=\"7JBWEY\">President-elect Donald Trump has said he plans to <a href=\"https://nrf.com/research/estimated-impacts-proposed-tariffs-imports-apparel-toys-furniture-household-appliances\">hike tariffs</a> on imported goods from China even more than his predecessor, which is expected to increase prices on everything from <a href=\"https://www.theverge.com/2024/11/6/24289494/trump-election-electric-vehicle-tax-credit-tesla-elon-musk\">cars</a> to <a href=\"https://www.theverge.com/2024/11/8/24291333/second-trump-tech-policy-antitrust-ai-crypto\">electronics</a>.</p>\n<p id=\"cPdgcD\"></p>\n<p id=\"WDVGQL\"></p>\n\n",
    "summary": "A worker handles wafers at the GCL Technology production plant in Xuzhou, Jiangsu Province, China, on Tuesday, July 2, 2024. GCL Technology is one of the world’s largest makers of polysilicon, a key material in solar panels. | Photo: Getty Images\n    \n\n  \nTariffs on solar wafers, polysilicon, and certain tungsten products from China are going to rise dramatically come January 1st, 2025, the Biden administration announced Wednesday. That means higher price tags on key materials needed to make solar panels at a time when solar is the fastest growing source of electricity in the US. \nPolysilicon is used to make solar wafers, which are the semiconductors in solar panels. Tungsten — the same material in old-school incandescent lightbulbs — has many uses in electronics because of its high melting point. The metal is also part of supply chains for the aerospace, automotive, defense, medical, and oil and gas industries.\nThat means higher price tags on key materials needed to make solar panels at a time when solar is the fastest growing source of electricity in the US\nIt’s the latest instance of the Biden administration hiking up tariffs on goods from China — which dominates solar manufacturing — as part of its plan to build up domestic supply chains for clean energy. \nSolar products from the Xinjiang region in particular also face accusations of forced labor and human rights abuses. The Office of the US Trade Representative (USTR) also said that the decision to raise tariffs follows an investigation into cyber theft and economic espionage by China.\n“The tariff increases announced today will further blunt the harmful policies and practices by the People’s Republic of China,” ambassador Katherine Tai said in a statement. “These actions will complement the domestic investments made under the Biden-Harris Administration to promote a clean energy economy, while increasing the resilience of critical supply chains.”\nStarting next year, tariffs on polysilicon and solar wafers will double from 25 to 50 percent. Tariffs on certain tungsten products will go from zero to 25 percent. Chinese companies produce more than 75 percent of the world’s polysilicon. Considering all the manufacturing stages for solar panels, which includes polysilicon and wafers, China holds more than 80 percent of global capacity.\nAmerican manufacturers welcomed the changes. “These trade measures will begin to counter the pervasive Chinese government subsidies in solar manufacturing. It is a step in the right direction,” Mike Carr, executive director of the Solar Energy Manufacturers for America (SEMA) Coalition, said in an emailed statement. \n\n\nTo be sure, Chinese policies aimed at boosting solar manufacturing have led to economies of scale that have allowed prices for solar panels to plummet around the world. Chinese companies also make much more affordable electric vehicles than US manufacturers. EVs from China have been similarly subject to soaring tariffs during the Biden administration to 100 percent from 25 percent this year. In May, Biden also announced that tariffs on battery parts and lithium-ion batteries would rise to 25 percent from 7.5 percent. In addition, he increased the tarifff rate on solar cells from 25 percent to 50 percent. And by 2025, the rate on semiconductors from China will double to 50 percent.\nPresident-elect Donald Trump has said he plans to hike tariffs on imported goods from China even more than his predecessor, which is expected to increase prices on everything from cars to electronics.",
    "author": "Justine Calma"
  },
  {
    "title": "YouTube quietly made some of its web embeds worse, including ours",
    "link": "https://www.theverge.com/2024/12/12/24318124/youtube-player-cant-click-title-sigh",
    "pubDate": "2024-12-12T16:35:23.000Z",
    "content": "  \n\n    <figure>\n      <img alt=\"The YouTube logo on a black background\" src=\"https://cdn.vox-cdn.com/thumbor/dxW-vEA6eR6CRvRhLNSmNnbu2Ek=/0x0:2040x1360/1310x873/cdn.vox-cdn.com/uploads/chorus_image/image/73782716/acastro_180322_1777_youtube_0001.0.jpg\" />\n        <figcaption>Illustration by Alex Castro / The Verge</figcaption>\n    </figure>\n\n  <p id=\"PCh2X3\">For about a year, I’ve gotten notes from readers asking why our YouTube embeds are broken in one very specific way: you can no longer click the title to open the video on YouTube.com or in the YouTube app. This used to work just fine, but now you can’t.</p>\n<p id=\"Uq47lY\">This bothers us, too, and it’s doubly frustrating because everyone assumes that <em>we’ve</em> chosen to disable links, which makes a certain kind of sense — after all, why on earth wouldn’t YouTube want people to click over to its app?</p>\n<p id=\"N24Sv2\">The short answer is money. Somewhat straightforwardly, YouTube has chosen to degrade the user experience of the embedded player publishers like Vox Media use, and the only way to get that link back is by using a slightly different player that pays us less and YouTube more.</p>\n<p id=\"pppz32\">I know this because I’ve spent months chasing down the mystery of the broken links, and after tons of back and forth between Vox Media’s teams and YouTube, and even me pushing this up to YouTube CEO Neal Mohan, they’re not going to change it.</p>\n<p id=\"MR6JxW\">Here’s the really long version: like everyone, we publish our videos on YouTube. But YouTube isn’t the same for everyone. Publishers like Vox Media can use something called the YouTube Player for Publishers, or PfP, which <a href=\"https://blog.google/outreach-initiatives/google-news-initiative/digital-news-initiative-introducing/\">has been around since 2016</a> and basically competes with the wacky custom video players you see on so many other sites. It allows publishers to sell their own ads at higher rates while still having the videos live in the YouTube ecosystem, which is a nice win-win and not something anyone had to think about until earlier this year. (I didn’t even really know about it until this links kerfuffle — if you <a href=\"https://www.theverge.com/2024/12/10/24317808/future-of-media-verge-subscription-podcasts-vergecast\">listen to <em>The Vergecast</em></a> this week, you know our newsroom is firewalled from the business side of our company.)</p>\n<p id=\"GWtjLm\">But around the beginning of this year, YouTube decided to change PfP and remove all of its branding from the publisher player. And “branding,” according to YouTube, includes that title link back to YouTube. If publishers want that link back to YouTube, they have to use the standard YouTube player — and give up their ad revenue and control to YouTube. That’s why so many YouTube players around the web — not just ours — don’t have links that work, even though they otherwise look and behave just like YouTube’s standard player.</p>\n<p id=\"R3VQVP\">Here’s what YouTube spokesperson Mariana De Felice told me about it: “News publishers can choose between the standard YouTube embedded player or a version designed specifically for them, which gives greater control over the ads experience, but removes YouTube branding and links back to YouTube. This version provides publishers greater control over the ads running on their videos, but YouTube doesn’t have visibility into which ads are served. In order to protect our advertisers and partners, we’ve removed our branding and links back to YouTube from the player.”</p>\n<p id=\"TjbT8F\">I am a real brat and have complained about this for months now — it had all worked fine since 2016! — but that’s the situation. Our choices are basically leaving things alone, making less money to have the link work, or switching to some other player on the site in protest, which would also not have a link back to YouTube but would at least let us pretend there’s market competition in video players. </p>\n<p id=\"GZzu6Y\">Ultimately our business side will make the call, but that’s why the link is broken — a tiny example of the modern platform internet that tells a huge story about how everything else works.</p>\n\n",
    "summary": "Illustration by Alex Castro / The Verge\n    \n\n  \nFor about a year, I’ve gotten notes from readers asking why our YouTube embeds are broken in one very specific way: you can no longer click the title to open the video on YouTube.com or in the YouTube app. This used to work just fine, but now you can’t.\nThis bothers us, too, and it’s doubly frustrating because everyone assumes that we’ve chosen to disable links, which makes a certain kind of sense — after all, why on earth wouldn’t YouTube want people to click over to its app?\nThe short answer is money. Somewhat straightforwardly, YouTube has chosen to degrade the user experience of the embedded player publishers like Vox Media use, and the only way to get that link back is by using a slightly different player that pays us less and YouTube more.\nI know this because I’ve spent months chasing down the mystery of the broken links, and after tons of back and forth between Vox Media’s teams and YouTube, and even me pushing this up to YouTube CEO Neal Mohan, they’re not going to change it.\nHere’s the really long version: like everyone, we publish our videos on YouTube. But YouTube isn’t the same for everyone. Publishers like Vox Media can use something called the YouTube Player for Publishers, or PfP, which has been around since 2016 and basically competes with the wacky custom video players you see on so many other sites. It allows publishers to sell their own ads at higher rates while still having the videos live in the YouTube ecosystem, which is a nice win-win and not something anyone had to think about until earlier this year. (I didn’t even really know about it until this links kerfuffle — if you listen to The Vergecast this week, you know our newsroom is firewalled from the business side of our company.)\nBut around the beginning of this year, YouTube decided to change PfP and remove all of its branding from the publisher player. And “branding,” according to YouTube, includes that title link back to YouTube. If publishers want that link back to YouTube, they have to use the standard YouTube player — and give up their ad revenue and control to YouTube. That’s why so many YouTube players around the web — not just ours — don’t have links that work, even though they otherwise look and behave just like YouTube’s standard player.\nHere’s what YouTube spokesperson Mariana De Felice told me about it: “News publishers can choose between the standard YouTube embedded player or a version designed specifically for them, which gives greater control over the ads experience, but removes YouTube branding and links back to YouTube. This version provides publishers greater control over the ads running on their videos, but YouTube doesn’t have visibility into which ads are served. In order to protect our advertisers and partners, we’ve removed our branding and links back to YouTube from the player.”\nI am a real brat and have complained about this for months now — it had all worked fine since 2016! — but that’s the situation. Our choices are basically leaving things alone, making less money to have the link work, or switching to some other player on the site in protest, which would also not have a link back to YouTube but would at least let us pretend there’s market competition in video players. \nUltimately our business side will make the call, but that’s why the link is broken — a tiny example of the modern platform internet that tells a huge story about how everything else works.",
    "author": "Nilay Patel"
  },
  {
    "title": "How to choose which Apple Watch to buy",
    "link": "https://www.theverge.com/23037217/best-apple-watch-series-se-ultra",
    "pubDate": "2024-12-12T16:32:03.000Z",
    "content": "  \n\n    <figure>\n      <img alt=\"Various models of Apple Watch on a graphic background.\" src=\"https://cdn.vox-cdn.com/thumbor/VP4_qF_XzWaJKVsKsOmHxZKZaeg=/0x0:2040x1360/1310x873/cdn.vox-cdn.com/uploads/chorus_image/image/70781237/247277_Buying_Guide_Apple_Watch_CVirginia.6.jpg\" />\n        <figcaption>Image: Cath Virginia. / The Verge</figcaption>\n    </figure>\n\n\n  <p>Between the Apple Watch Series 10, the Ultra 2, and the second-gen SE, there are more options than ever. We’ll help you sort through them.</p>\n  <p><a href=\"https://www.theverge.com/23037217/best-apple-watch-series-se-ultra\">Read the full story at The Verge.</a></p>\n\n",
    "summary": "Image: Cath Virginia. / The Verge\n    \n\n\n  \nBetween the Apple Watch Series 10, the Ultra 2, and the second-gen SE, there are more options than ever. We’ll help you sort through them.\nRead the full story at The Verge.",
    "author": "Victoria Song"
  },
  {
    "title": "BuzzFeed is selling Hot Ones",
    "link": "https://www.theverge.com/2024/12/12/24319564/buzzfeed-hot-ones-first-we-feast-sale",
    "pubDate": "2024-12-12T16:02:35.000Z",
    "content": "  \n\n    <figure>\n      <img alt=\"A bald man in a black shirt sitting at a table in front of a plate of buffalo wings and an assortment of hot sauces.\" src=\"https://cdn.vox-cdn.com/thumbor/VezUF4NsqcA_2Kgwvg5pejnTc9o=/292x0:2589x1531/1310x873/cdn.vox-cdn.com/uploads/chorus_image/image/73782641/Screenshot_2024_12_12_at_9.41.15_AM.0.png\" />\n        <figcaption>First We Feast.</figcaption>\n    </figure>\n\n  <p id=\"SYUq78\">After months of <a href=\"https://www.theverge.com/2024/6/24/24184695/everyone-wants-to-be-on-hot-ones-no-one-wants-to-buy-it\">searching for a buyer to take First We Feast</a> — the production company behind <em>Hot Ones</em> — off its hands, <a href=\"https://www.theverge.com/2023/4/20/23691169/buzzfeed-news-shut-down-jonah-peretti-memo\">BuzzFeed</a> has finally secured an $82.5 million all-cash deal to sell First We Feast to “a consortium led by an affiliate of Soros Fund Management LLC” The consortium’s list of investors includes First We Feast founder Chris Schonberger and <em>Hot Ones </em>host Sean Evans. </p>\n<p id=\"qNbU2S\">In <a href=\"https://investors.buzzfeed.com/news-releases/news-release-details/buzzfeed-inc-announces-sale-first-we-feast-affiliate-soros-fund\">a press release</a>, BuzzFeed CEO Jonah Peretti said that selling off First We Feast “marks an important step in BuzzFeed, Inc.’s strategic transformation into a media company positioned to fully benefit from the ongoing AI revolution.” </p>\n<p id=\"EkTPzU\">“In the coming years, we will continue to invest in our most scalable and tech enabled services, launching new AI-powered interactive experiences, and delivering for our loyal audience and business partners,” Peretti said.</p>\n<div class=\"c-float-left c-float-hang\"><aside id=\"icVZJn\"><div data-anthem-component=\"readmore\" data-anthem-component-data='{\"stories\":[{\"title\":\"Inside Hot Ones, the wildly popular and violently spicy YouTube show\",\"url\":\"https://www.theverge.com/2019/10/31/20938739/hot-ones-sean-evans-youtube-guests-gordon-ramsey-idris-elba-late-night-tv\"}]}'></div></aside></div>\n<p id=\"DvAi2S\">BuzzFeed acquired First We Feast in 2021 when it bought rival media outfit Complex, the production company’s original owner. Though BuzzFeed wound up <a href=\"https://variety.com/2024/digital/news/buzzfeed-sells-complex-ntwrk-layoffs-1235918498/\">selling Complex off to Ntwrk</a> earlier this year for $108.6 million, it elected to retain control of First We Feast.</p>\n<p id=\"gud0sL\">The deal comes after <a href=\"https://www.businessinsider.com/buzzfeed-debt-due-hot-ones-deadline-2024-12\">months of speculation</a> about how BuzzFeed might go about paying down $123.5 million in debt and interest payments. <a href=\"https://www.msnbc.com/the-reidout/reidout-blog/vivek-ramaswamy-drops-out-takeaways-republicans-rcna134194\">Failed Republican presidential candidate</a> and <a href=\"https://www.theverge.com/2024/11/12/24295165/trump-elon-musk-doge-cut-government-spending\">soon-to-be DOGE co-head Vivek Ramaswamy</a> (who recently purchased a 9 percent stake in BuzzFeed) <a href=\"https://www.theverge.com/2024/5/28/24166644/vivek-ramaswamy-buzzfeed-letter-shares\">previously insisted</a> that BuzzFeed wouldn’t be able to get on top of its debt problem and that he could somehow end up running the company. </p>\n<p id=\"lu3Tzt\">However, with cash on hand plus $75.6 from this sale, Buzzfeed says it can pay down the debt, and end up with more cash on its books than debt.</p>\n\n",
    "summary": "First We Feast.\n    \n\n  \nAfter months of searching for a buyer to take First We Feast — the production company behind Hot Ones — off its hands, BuzzFeed has finally secured an $82.5 million all-cash deal to sell First We Feast to “a consortium led by an affiliate of Soros Fund Management LLC” The consortium’s list of investors includes First We Feast founder Chris Schonberger and Hot Ones host Sean Evans. \nIn a press release, BuzzFeed CEO Jonah Peretti said that selling off First We Feast “marks an important step in BuzzFeed, Inc.’s strategic transformation into a media company positioned to fully benefit from the ongoing AI revolution.” \n“In the coming years, we will continue to invest in our most scalable and tech enabled services, launching new AI-powered interactive experiences, and delivering for our loyal audience and business partners,” Peretti said.\n\n\nBuzzFeed acquired First We Feast in 2021 when it bought rival media outfit Complex, the production company’s original owner. Though BuzzFeed wound up selling Complex off to Ntwrk earlier this year for $108.6 million, it elected to retain control of First We Feast.\nThe deal comes after months of speculation about how BuzzFeed might go about paying down $123.5 million in debt and interest payments. Failed Republican presidential candidate and soon-to-be DOGE co-head Vivek Ramaswamy (who recently purchased a 9 percent stake in BuzzFeed) previously insisted that BuzzFeed wouldn’t be able to get on top of its debt problem and that he could somehow end up running the company. \nHowever, with cash on hand plus $75.6 from this sale, Buzzfeed says it can pay down the debt, and end up with more cash on its books than debt.",
    "author": "Charles Pulliam-Moore"
  },
  {
    "title": "Google announces Android XR, a new OS for headsets and smart glasses",
    "link": "https://www.theverge.com/2024/12/12/24319538/google-android-xr-ar-vr-smart-glasses",
    "pubDate": "2024-12-12T16:00:00.000Z",
    "content": "  \n\n    <figure>\n      <img alt=\"The Android XR logo over several app screenshots.\" src=\"https://cdn.vox-cdn.com/thumbor/vsPScKNTerkRgjSpu6vKTp6zLPc=/39x0:473x289/1310x873/cdn.vox-cdn.com/uploads/chorus_image/image/73782605/Keyword_Blog_Hero.0.png\" />\n        <figcaption><em>XR stands for “extended reality,” which you should get used to explaining to lots of people.</em> | Image: Google</figcaption>\n    </figure>\n\n  <p id=\"jA2Y0a\">Google is taking another run at making headsets work. The company <a href=\"https://blog.google/products/android/android-xr\">just announced Android XR</a>, a new operating system designed specifically for what Google calls “extended reality” devices like headsets and glasses. It’s working with Samsung and lots of other hardware manufacturers to develop those headsets and glasses, is making the new version of Android available to developers now, and hopes to start shipping XR stuff next year.</p>\n<p id=\"2EovuJ\">We don’t yet have a ton of details on exactly how Android XR will work or how it might differ from the Android on your phone. (<em>The Verge</em>’s<em> </em>Victoria Song got to try a few demos and prototypes — make sure you read <a href=\"https://www.theverge.com/e/24083569\">her story</a>.) Google is making immersive XR versions of apps like Maps, Photos, and YouTube and says it’s developing a version of Chrome that lets you do multiwindow multitasking in your browser. It will also support existing phone and tablet apps from the Play Store, much in the same way Apple supports iPad apps <a href=\"https://www.theverge.com/24054862/apple-vision-pro-review-vr-ar-headset-features-price\">in the Vision Pro</a>. </p>\n<p id=\"qSujAM\"><a href=\"https://www.theverge.com/2024/12/11/24317436/google-deepmind-project-astra-mariner-ai-agent\">Google’s Gemini AI</a>, of course, is at the very center of the whole experience. Google has been trying to crack headsets for more than a decade — there was <a href=\"https://www.theverge.com/2013/2/22/4013406/i-used-google-glass-its-the-future-with-monthly-updates\">Glass</a> and <a href=\"https://www.theverge.com/2014/12/10/7374521/google-throws-its-weight-behind-cheap-cardboard-virtual-reality\">Cardboard</a> and <a href=\"https://www.theverge.com/2016/11/18/13670182/how-google-daydream-view-vr-headset-was-made\">Daydream</a>, all of which had good ideas but none of which turned into much — and the company thinks AI is the key to making the user experience work. “We believe a digital assistant integrated with your XR experience is the killer app for the form factor, like what email or texting was for the smartphone,” said Sameer Samat, who oversees the Android ecosystem at Google, in a press briefing ahead of the launch. As Gemini becomes more multimodal, too, able to both capture and create audio and video, glasses and headsets suddenly make much more sense.</p>\n<figure class=\"e-image\">\n        <img alt=\"A photo of a text message displayed in AR over a real-wrold street.\" data-mask-text=\"false\" src=\"https://cdn.vox-cdn.com/thumbor/oQRXZN0CXfR2WPupiZNpSgewfw0=/400x0/filters:no_upscale()/cdn.vox-cdn.com/uploads/chorus_asset/file/25786860/Screenshot_2024_12_12_at_09.05.29.png\">\n      <cite>Image: Google</cite>\n      <figcaption><em>This is the kind of AR interface you’ll get with Android XR.</em></figcaption>\n  </figure>\n<p id=\"vfrg01\">The choice of the term “XR” for the OS is maybe the most interesting part. There are a million terms and acronyms for this space: there’s virtual reality, augmented reality, mixed reality, extended reality, and others, all of which mean different but overlapping things. XR is probably the broadest of the terms, which seems to be why Google picked it. “When we say extended reality or XR,” Samat said, “we’re really talking about a whole spectrum of experiences, from virtual reality to augmented reality and everything in between.” </p>\n<p id=\"AMunsB\">Google imagines headsets that can seamlessly transition from virtual worlds to real ones — again like the Vision Pro — and smart glasses that are more of an always-on companion. It’s also interested in audio-only devices like the Ray-Ban Meta Smart Glasses. Some things might be standalone; others might be more like an accessory to your phone. We’ll see if Google ends up building its own XR hardware, but it’s clearly trying to support a huge spectrum of devices.</p>\n<p id=\"PwfGk7\">Android XR is still in its early stages, and most developers are only now going to start getting the software and hardware they need to build for the new OS. But Google’s trying to move quickly next year: a device it’s building with Samsung, codenamed Moohan, is apparently slated to ship next year. Android XR is, in some ways, a culmination of bets Google has been making in AI, the broader Android ecosystem, and the wearable future of technology. All of those bets are about to get the real test: whether anyone actually puts them on.</p>\n<p id=\"RN3OtG\"> </p>\n\n",
    "summary": "XR stands for “extended reality,” which you should get used to explaining to lots of people. | Image: Google\n    \n\n  \nGoogle is taking another run at making headsets work. The company just announced Android XR, a new operating system designed specifically for what Google calls “extended reality” devices like headsets and glasses. It’s working with Samsung and lots of other hardware manufacturers to develop those headsets and glasses, is making the new version of Android available to developers now, and hopes to start shipping XR stuff next year.\nWe don’t yet have a ton of details on exactly how Android XR will work or how it might differ from the Android on your phone. (The Verge’s Victoria Song got to try a few demos and prototypes — make sure you read her story.) Google is making immersive XR versions of apps like Maps, Photos, and YouTube and says it’s developing a version of Chrome that lets you do multiwindow multitasking in your browser. It will also support existing phone and tablet apps from the Play Store, much in the same way Apple supports iPad apps in the Vision Pro. \nGoogle’s Gemini AI, of course, is at the very center of the whole experience. Google has been trying to crack headsets for more than a decade — there was Glass and Cardboard and Daydream, all of which had good ideas but none of which turned into much — and the company thinks AI is the key to making the user experience work. “We believe a digital assistant integrated with your XR experience is the killer app for the form factor, like what email or texting was for the smartphone,” said Sameer Samat, who oversees the Android ecosystem at Google, in a press briefing ahead of the launch. As Gemini becomes more multimodal, too, able to both capture and create audio and video, glasses and headsets suddenly make much more sense.\nImage: Google\n      This is the kind of AR interface you’ll get with Android XR.\n  \nThe choice of the term “XR” for the OS is maybe the most interesting part. There are a million terms and acronyms for this space: there’s virtual reality, augmented reality, mixed reality, extended reality, and others, all of which mean different but overlapping things. XR is probably the broadest of the terms, which seems to be why Google picked it. “When we say extended reality or XR,” Samat said, “we’re really talking about a whole spectrum of experiences, from virtual reality to augmented reality and everything in between.” \nGoogle imagines headsets that can seamlessly transition from virtual worlds to real ones — again like the Vision Pro — and smart glasses that are more of an always-on companion. It’s also interested in audio-only devices like the Ray-Ban Meta Smart Glasses. Some things might be standalone; others might be more like an accessory to your phone. We’ll see if Google ends up building its own XR hardware, but it’s clearly trying to support a huge spectrum of devices.\nAndroid XR is still in its early stages, and most developers are only now going to start getting the software and hardware they need to build for the new OS. But Google’s trying to move quickly next year: a device it’s building with Samsung, codenamed Moohan, is apparently slated to ship next year. Android XR is, in some ways, a culmination of bets Google has been making in AI, the broader Android ecosystem, and the wearable future of technology. All of those bets are about to get the real test: whether anyone actually puts them on.",
    "author": "David Pierce"
  },
  {
    "title": "I saw Google’s plan to put Android on your face",
    "link": "https://www.theverge.com/2024/12/12/24319528/google-android-xr-samsung-project-moohan-smart-glasses",
    "pubDate": "2024-12-12T16:00:00.000Z",
    "content": "  \n\n    <figure>\n      <img alt=\"Screencap of Gemini summarizing a text in AR smart glasses\" src=\"https://cdn.vox-cdn.com/thumbor/-JTn5YoOK4IhuwUnMKkrVJjYUmk=/14x0:2027x1342/1310x873/cdn.vox-cdn.com/uploads/chorus_image/image/73782611/androidxr.0.jpg\" />\n        <figcaption><em>Google didn’t let me take my own photos, but this is strikingly similar to the demo I saw with my own eyes.</em> | Image: Google</figcaption>\n    </figure>\n\n\n  <p>I demoed Google’s new Android XR platform, Samsung’s Project Moohan, and prototype smart glasses. I felt as close to Tony Stark in a controlled demo as I’ll ever be.</p> <p class=\"p--has-dropcap p-large-text\" id=\"fX5RZv\">It’s an ordinary Tuesday. I’m wearing what look like ordinary glasses in a room surrounded by Google and Samsung representatives. One of them steps out in front of me and starts speaking in Spanish. I don’t speak Spanish. Hovering in mid-air, I can see her words being translated into English subtitles. Reading them, I can see she’s describing what I’m seeing in real time.</p>\n<p id=\"qvWlkI\">I mumble an expletive. Everyone laughs.</p>\n<p id=\"BoR2MH\">This is my first experience with Android XR — a new mixed reality OS designed for headsets and smart glasses, like the prototypes I’m wearing. It’s Google’s big bet to power a new generation of augmented reality devices that embody all our wildest dreams of what smart glasses can be.</p>\n<div class=\"c-float-left c-float-hang\"><aside id=\"ncIWDc\"><div data-anthem-component=\"readmore\" data-anthem-component-data='{\"stories\":[{\"title\":\"It sure sounds like Google is planning to actually launch some smart glasses \",\"url\":\"https://www.theverge.com/2024/12/11/24318672/google-smart-glasses-ai-gemini\"},{\"title\":\"Project Astra is the future of AI at Google \",\"url\":\"https://www.theverge.com/2024/5/14/24156296/google-ai-gemini-astra-assistant-live-io\"}]}'></div></aside></div>\n<p id=\"Smx3az\">Google is no stranger to augmented reality. Google Glass crashed and burned with the public more than 10 years ago before being <a href=\"https://www.theverge.com/2019/5/20/18632689/google-glass-enterprise-edition-2-augmented-reality-headset-pricing\">repurposed for enterprise users</a> and <a href=\"https://www.theverge.com/2023/3/15/23641872/google-glass-enterprise-edition-discontinued-support\">eventually discontinued</a>. But things are different now. Apple has the <a href=\"https://www.theverge.com/24054862/apple-vision-pro-review-vr-ar-headset-features-price\">Vision Pro</a>. Meta has the <a href=\"https://www.theverge.com/23922425/ray-ban-meta-smart-glasses-review\">Ray-Ban smart glasses</a>, and their <a href=\"https://www.theverge.com/2024/4/23/24138090/ray-ban-meta-smart-glasses-ai-wearables\">AI features</a> have garnered positive buzz. That’s why Google is jumping back into the fray with Android XR.</p>\n<p id=\"CLrByG\">Google wants everyone to know the time is finally right for XR, and<strong> </strong>it’s pointing to Gemini as its north star. Adding Gemini enables multimodal AI and natural language — things it says will make interactions with your environment richer. In a demo, Google had me prompt Gemini to name the title of a yellow book sitting behind me on a shelf. I’d briefly glanced at it earlier but hadn’t taken a photo. Gemini took a second, and then offered up an answer. I whipped around to check — it was correct.</p>\n<p id=\"6xEfYG\">On top of that, the platform will work with any mobile and tablet app from the Play Store out of the box. Today’s launch is aimed at developers so they can start building out experiences. The average person won’t be able to buy anything running Android XR right now, but in 2025, Samsung will be launching its long-rumored XR headset. Dubbed Project Moohan (Korean for infinity), the headset will be the first consumer product to ship with Android XR. Technically, it’s running the same software as the glasses I tried, but Project Moohan will also be capable of VR and immersive content — stuff that wouldn’t be suited to a pair of smart glasses. It’s essentially a showcase for everything that <em>could</em> be possible. Hence why Google is going with XR — a catch-all term that stands for “extended reality” and encompasses AR, VR, and mixed reality.</p>\n<div class=\"c-wide-block\">\n<figure class=\"e-image\">\n        <img alt=\"Render of Project Moohan\" data-mask-text=\"false\" src=\"https://cdn.vox-cdn.com/thumbor/1MY6-5d8W4L5s0McaHf8XBaZ_TY=/400x0/filters:no_upscale()/cdn.vox-cdn.com/uploads/chorus_asset/file/25786842/Project_Moohan_Side.jpg\">\n      <cite>Image: Google, Samsung</cite>\n      <figcaption><em>Project Moohan felt like a mix between a Meta Quest 3 and Vision Pro headset.</em></figcaption>\n  </figure>\n</div>\n<p id=\"DXEkHC\">Samsung’s headset feels like a mix between a Meta Quest 3 and the Vision Pro. Unlike either, the light seal is optional so you can choose to let the world bleed in. It’s lightweight and doesn’t pinch my face too tightly. My ponytail easily slots through the top, and later, I’m thankful that I don’t have to redo my hair. At first, the resolution doesn’t feel quite as sharp as the Vision Pro — until the headset automatically calibrates to my pupillary distance. </p>\n<p id=\"4AdAxU\">It’s at this point when I start feeling deja vu. I’m walked through pinching to select items and how to tap the side to bring up the app launcher. There’s an eye calibration process that feels awfully similar to the Vision Pro’s. If I want, I can retreat into an immersive mode to watch YouTube and Google TV on a distant mountain. I can open apps, resize them, and place them at various points around the room. I’ve done this all before. This just happens to be Google-flavored. </p>\n<p id=\"cp5uT3\">I want to ask: how do you expect to stand out?</p>\n<p id=\"qrTIAR\">I don’t get the chance to before I’m told: Gemini. </p>\n<hr class=\"p-entry-hr\" id=\"9ZL3Ls\">\n<p class=\"p--has-dropcap\" id=\"XAmLQy\">For the skeptic, it’s easy to scoff at the idea that <em>Gemini</em>, of all things, is what’s going to crack the augmented reality puzzle. Generative AI is having a moment right now, but <a href=\"https://www.theverge.com/2024/2/21/24079371/google-ai-gemini-generative-inaccurate-historical\">not always in a positive way</a>. Outside of conferences filled with tech evangelists, AI is often viewed with derision and suspicion. But inside the Project Moohan headset or wearing a pair of prototype smart glasses? I can catch a glimpse of why Google and Samsung believe Gemini is the killer app for XR.</p>\n<p id=\"hTHQmT\">For me, it’s the fact that I don’t have to be specific when I ask for things. Usually, I get flustered talking to AI assistants because I have to remember the wake word, clearly phrase my request, and sometimes even specify my preferred app. </p>\n<p id=\"bYr4Gs\">“One thing I’m really confident about, something that’s not just different from before, is that Gemini is really <em>that</em> great,” says Kihwan Kim, EVP at Samsung Electronics, who nods furiously in agreement when I mention this. To Kim, it’s the ability to fluidly speak to Gemini and the fact that it understands a person’s individual context that opens dozens of different options for the way each person interacts with XR. “That’s why I clearly see that this headset will give more insight about what [XR] <em>should</em> be.” </p>\n<div id=\"J5UaVE\">\n<div data-analytics-viewport=\"video\" data-analytics-action=\"volume:view:article:middle\" data-analytics-label=\"Android XR Translation|118723\" data-volume-uuid=\"a0951b61e\" data-volume-id=\"118723\" data-analytics-placement=\"article:middle\" data-volume-placement=\"article\" data-volume-autoplay=\"false\" id=\"volume-placement-297\" class=\"volume-video\" data-volume-player-choice=\"chorus\"></div>\n<div class=\"caption\"><em>I was shocked at how well my translation demos went, which were in the same spirit as the video here.</em></div>\n</div>\n<p id=\"4G3Sz0\">In the Moohan headset, I can say, “Take me to JYP Entertainment in Seoul,” and it will automatically open Google Maps and show me that building. If my windows get cluttered, I can ask it to reorganize them. I don’t have to lift a finger. While wearing the prototype glasses, I watch and listen as Gemini summarizes a long, rambling text message to the main point: can you buy lemon, ginger, and olive oil from the store? I was able to naturally switch from speaking in English to asking in Japanese what the weather is in New York — and get the answer in spoken and written Japanese.</p>\n<p id=\"rveYXr\">It’s not just interactions with Gemini that linger in my mind, either. It’s also how experiences can be built on top of them. I asked Gemini how to get somewhere and saw turn-by-turn text directions. When I looked down, the text morphed into a zoomable map of my surroundings. It’s very easy to imagine myself using something like that in real life.</p>\n<p id=\"i0V1gX\">But as cool as all that is, headsets can be a hard sell to the average person. Personally, I’m more enamored with the glasses demo, but those have no concrete timeline. (Google made the prototypes, but it’s focusing on working with other partners to bring hardware to market.) There are still cultural cues that have to be established with either form factor. Outside of Gemini, there has to be a robust ecosystem of apps and experiences for the average person, not just early adopters.</p>\n<div id=\"Q6fJyD\">\n<div data-analytics-viewport=\"video\" data-analytics-action=\"volume:view:article:middle\" data-analytics-label=\"Android XR headset circle to search|118724\" data-volume-uuid=\"05ffcc3a3\" data-volume-id=\"118724\" data-analytics-placement=\"article:middle\" data-volume-placement=\"article\" data-volume-autoplay=\"false\" id=\"volume-placement-623\" class=\"volume-video\" data-volume-player-choice=\"chorus\"></div>\n<div class=\"caption\"><em>The headset demos felt more familiar, though Circle to Search was unique to Android XR.</em></div>\n</div>\n<p id=\"0Nbe6b\">“It’s not going to be a singular product. It’s Android,” says Shahram Izadi, Google’s VP of AR and XR, noting that Google has a three-pronged strategy for Android XR: laying the groundwork with devs is one element; Gemini’s conversational experience is another; and the third is the idea that no one device is the future of XR. Headsets, for example, may just be “episodic” devices you use for entertainment. Glasses could supplement phones and smartwatches for discreet notifications and looking up information.</p>\n<p id=\"KeC7Qs\">“The way I see it, these devices don’t replace one another. You’ll use these devices throughout your day, and if there’s consistency with Gemini and generative AI experiences across these form factors, people will get more comfortable with wearing computers on their faces. That’s the on ramp to get to more immersive devices,” says Izadi. </p>\n<p id=\"M5NkXh\">Listening to Kim and Izadi talk, I want to believe. But I’m also acutely aware that all of my experiences were tightly controlled. I wasn’t given free rein to try and break things. I couldn’t take photos of the headset or glasses. At every point, I was carefully guided through preapproved demos that Google and Samsung were reasonably sure would work. I — and every other consumer — can’t <em>fully</em> believe until we can play with these things without guardrails.</p>\n<p class=\"c-end-para\" id=\"65ogAn\">But even knowing that, I can’t deny that, for an hour, I felt like Tony Stark with Gemini as my Jarvis. For better or worse, this example has molded so much of our expectations for how XR and AI assistants should work. I’ve tried dozens of headsets and smart glasses that promised to make what I see in the movies real — and utterly failed. For the first time, I experienced something relatively close.</p>\n<p id=\"up9xgc\"></p>\n<p id=\"Jh2DHJ\"></p>\n\n",
    "summary": "Google didn’t let me take my own photos, but this is strikingly similar to the demo I saw with my own eyes. | Image: Google\n    \n\n\n  \nI demoed Google’s new Android XR platform, Samsung’s Project Moohan, and prototype smart glasses. I felt as close to Tony Stark in a controlled demo as I’ll ever be.\n It’s an ordinary Tuesday. I’m wearing what look like ordinary glasses in a room surrounded by Google and Samsung representatives. One of them steps out in front of me and starts speaking in Spanish. I don’t speak Spanish. Hovering in mid-air, I can see her words being translated into English subtitles. Reading them, I can see she’s describing what I’m seeing in real time.\nI mumble an expletive. Everyone laughs.\nThis is my first experience with Android XR — a new mixed reality OS designed for headsets and smart glasses, like the prototypes I’m wearing. It’s Google’s big bet to power a new generation of augmented reality devices that embody all our wildest dreams of what smart glasses can be.\n\n\nGoogle is no stranger to augmented reality. Google Glass crashed and burned with the public more than 10 years ago before being repurposed for enterprise users and eventually discontinued. But things are different now. Apple has the Vision Pro. Meta has the Ray-Ban smart glasses, and their AI features have garnered positive buzz. That’s why Google is jumping back into the fray with Android XR.\nGoogle wants everyone to know the time is finally right for XR, and it’s pointing to Gemini as its north star. Adding Gemini enables multimodal AI and natural language — things it says will make interactions with your environment richer. In a demo, Google had me prompt Gemini to name the title of a yellow book sitting behind me on a shelf. I’d briefly glanced at it earlier but hadn’t taken a photo. Gemini took a second, and then offered up an answer. I whipped around to check — it was correct.\nOn top of that, the platform will work with any mobile and tablet app from the Play Store out of the box. Today’s launch is aimed at developers so they can start building out experiences. The average person won’t be able to buy anything running Android XR right now, but in 2025, Samsung will be launching its long-rumored XR headset. Dubbed Project Moohan (Korean for infinity), the headset will be the first consumer product to ship with Android XR. Technically, it’s running the same software as the glasses I tried, but Project Moohan will also be capable of VR and immersive content — stuff that wouldn’t be suited to a pair of smart glasses. It’s essentially a showcase for everything that could be possible. Hence why Google is going with XR — a catch-all term that stands for “extended reality” and encompasses AR, VR, and mixed reality.\nImage: Google, Samsung\n      Project Moohan felt like a mix between a Meta Quest 3 and Vision Pro headset.\n  \n\nSamsung’s headset feels like a mix between a Meta Quest 3 and the Vision Pro. Unlike either, the light seal is optional so you can choose to let the world bleed in. It’s lightweight and doesn’t pinch my face too tightly. My ponytail easily slots through the top, and later, I’m thankful that I don’t have to redo my hair. At first, the resolution doesn’t feel quite as sharp as the Vision Pro — until the headset automatically calibrates to my pupillary distance. \nIt’s at this point when I start feeling deja vu. I’m walked through pinching to select items and how to tap the side to bring up the app launcher. There’s an eye calibration process that feels awfully similar to the Vision Pro’s. If I want, I can retreat into an immersive mode to watch YouTube and Google TV on a distant mountain. I can open apps, resize them, and place them at various points around the room. I’ve done this all before. This just happens to be Google-flavored. \nI want to ask: how do you expect to stand out?\nI don’t get the chance to before I’m told: Gemini. \nFor the skeptic, it’s easy to scoff at the idea that Gemini, of all things, is what’s going to crack the augmented reality puzzle. Generative AI is having a moment right now, but not always in a positive way. Outside of conferences filled with tech evangelists, AI is often viewed with derision and suspicion. But inside the Project Moohan headset or wearing a pair of prototype smart glasses? I can catch a glimpse of why Google and Samsung believe Gemini is the killer app for XR.\nFor me, it’s the fact that I don’t have to be specific when I ask for things. Usually, I get flustered talking to AI assistants because I have to remember the wake word, clearly phrase my request, and sometimes even specify my preferred app. \n“One thing I’m really confident about, something that’s not just different from before, is that Gemini is really that great,” says Kihwan Kim, EVP at Samsung Electronics, who nods furiously in agreement when I mention this. To Kim, it’s the ability to fluidly speak to Gemini and the fact that it understands a person’s individual context that opens dozens of different options for the way each person interacts with XR. “That’s why I clearly see that this headset will give more insight about what [XR] should be.” \n\nI was shocked at how well my translation demos went, which were in the same spirit as the video here.\nIn the Moohan headset, I can say, “Take me to JYP Entertainment in Seoul,” and it will automatically open Google Maps and show me that building. If my windows get cluttered, I can ask it to reorganize them. I don’t have to lift a finger. While wearing the prototype glasses, I watch and listen as Gemini summarizes a long, rambling text message to the main point: can you buy lemon, ginger, and olive oil from the store? I was able to naturally switch from speaking in English to asking in Japanese what the weather is in New York — and get the answer in spoken and written Japanese.\nIt’s not just interactions with Gemini that linger in my mind, either. It’s also how experiences can be built on top of them. I asked Gemini how to get somewhere and saw turn-by-turn text directions. When I looked down, the text morphed into a zoomable map of my surroundings. It’s very easy to imagine myself using something like that in real life.\nBut as cool as all that is, headsets can be a hard sell to the average person. Personally, I’m more enamored with the glasses demo, but those have no concrete timeline. (Google made the prototypes, but it’s focusing on working with other partners to bring hardware to market.) There are still cultural cues that have to be established with either form factor. Outside of Gemini, there has to be a robust ecosystem of apps and experiences for the average person, not just early adopters.\n\nThe headset demos felt more familiar, though Circle to Search was unique to Android XR.\n“It’s not going to be a singular product. It’s Android,” says Shahram Izadi, Google’s VP of AR and XR, noting that Google has a three-pronged strategy for Android XR: laying the groundwork with devs is one element; Gemini’s conversational experience is another; and the third is the idea that no one device is the future of XR. Headsets, for example, may just be “episodic” devices you use for entertainment. Glasses could supplement phones and smartwatches for discreet notifications and looking up information.\n“The way I see it, these devices don’t replace one another. You’ll use these devices throughout your day, and if there’s consistency with Gemini and generative AI experiences across these form factors, people will get more comfortable with wearing computers on their faces. That’s the on ramp to get to more immersive devices,” says Izadi. \nListening to Kim and Izadi talk, I want to believe. But I’m also acutely aware that all of my experiences were tightly controlled. I wasn’t given free rein to try and break things. I couldn’t take photos of the headset or glasses. At every point, I was carefully guided through preapproved demos that Google and Samsung were reasonably sure would work. I — and every other consumer — can’t fully believe until we can play with these things without guardrails.\nBut even knowing that, I can’t deny that, for an hour, I felt like Tony Stark with Gemini as my Jarvis. For better or worse, this example has molded so much of our expectations for how XR and AI assistants should work. I’ve tried dozens of headsets and smart glasses that promised to make what I see in the movies real — and utterly failed. For the first time, I experienced something relatively close.",
    "author": "Victoria Song"
  },
  {
    "title": "The Indian audio app spinning its own stories",
    "link": "https://www.theverge.com/24317729/pocket-fm-audio-stories-creators-insta-millionaire",
    "pubDate": "2024-12-12T16:00:00.000Z",
    "content": "  \n\n    <figure>\n      <img alt=\"Audiobook files being created on a factory conveyor belt.\" src=\"https://cdn.vox-cdn.com/thumbor/FEoAujNV2Jx_T79q-af0NGFAPhQ=/0x0:2040x1360/1310x873/cdn.vox-cdn.com/uploads/chorus_image/image/73782609/247398_Pocket_FM_CVirginia_A.0.jpg\" />\n        <figcaption>Image: Cath Virginia, Adobe Stock</figcaption>\n    </figure>\n\n\n  <p>The Indian storytelling app gives its audience an unending stream of audio stories about lucky individuals who become rich. It might as well be an allegory for its own creator economy.</p>\n  <p><a href=\"https://www.theverge.com/24317729/pocket-fm-audio-stories-creators-insta-millionaire\">Read the full story at The Verge.</a></p>\n\n",
    "summary": "Image: Cath Virginia, Adobe Stock\n    \n\n\n  \nThe Indian storytelling app gives its audience an unending stream of audio stories about lucky individuals who become rich. It might as well be an allegory for its own creator economy.\nRead the full story at The Verge.",
    "author": "Kudrat Wadhwa"
  },
  {
    "title": "Kia drivers are going to get Google Maps data soon",
    "link": "https://www.theverge.com/2024/12/12/24319513/hyundai-kia-genesis-google-maps-places-api-integration",
    "pubDate": "2024-12-12T15:53:16.000Z",
    "content": "  \n\n    <figure>\n      <img alt=\"Kia EV9\" src=\"https://cdn.vox-cdn.com/thumbor/2yIBoKOSHrL5girPcXGJJyHz2o4=/0x0:2700x1800/1310x873/cdn.vox-cdn.com/uploads/chorus_image/image/73782591/247053_Kia_EV9_AHawkins_0001.0.jpg\" />\n        <figcaption>Photo by Andrew J. Hawkins / The Verge</figcaption>\n    </figure>\n\n  <p id=\"0SWPfq\">Hyundai and Kia will <a href=\"https://www.kiamedia.com/us/en/media/pressreleases/22941/hyundai-motor-group-and-google-collaborate-on-software-capability-for-future-mobility-innovation\">integrate Google Maps data</a> into their current vehicle infotainment platforms ahead of a switchover to the Android Automotive operating system, the automakers announced today. </p>\n<p id=\"oiBtpU\">Hyundai, Kia, and the luxury nameplate Genesis will use Google Maps Platform’s Places API to inject 250 million points of interest into the existing navigation software. Kia will be the first to get the new data integration in North America, with “subsequent expansions” to other Hyundai, Kia, and Genesis models globally. Hyundai says the changes are part of an ongoing Google partnership that accelerates their development of what the automaker calls “software-defined vehicles,” or SDV.</p>\n<p id=\"lyOLTm\">We asked Hyundai if current models on the road will get Google Maps data through a software update and will update this story when we get a response. The current navigation app for the companies primarily uses points of interest data from digital mapping company TomTom. Tesla is also one of several automakers that has its own navigation software on a closed OS but <a href=\"https://www.teslarati.com/tesla-voyage-trip-planner-map-caraoke-recording-update/\">uses Places API for mapping data</a>.</p>\n<p id=\"666IVk\">However, Hyundai, Kia, and Genesis will soon follow the industry-wide trend of moving to Google’s Android...</p>\n  <p><a href=\"https://www.theverge.com/2024/12/12/24319513/hyundai-kia-genesis-google-maps-places-api-integration\">Read the full story at The Verge.</a></p>\n\n",
    "summary": "Photo by Andrew J. Hawkins / The Verge\n    \n\n  \nHyundai and Kia will integrate Google Maps data into their current vehicle infotainment platforms ahead of a switchover to the Android Automotive operating system, the automakers announced today. \nHyundai, Kia, and the luxury nameplate Genesis will use Google Maps Platform’s Places API to inject 250 million points of interest into the existing navigation software. Kia will be the first to get the new data integration in North America, with “subsequent expansions” to other Hyundai, Kia, and Genesis models globally. Hyundai says the changes are part of an ongoing Google partnership that accelerates their development of what the automaker calls “software-defined vehicles,” or SDV.\nWe asked Hyundai if current models on the road will get Google Maps data through a software update and will update this story when we get a response. The current navigation app for the companies primarily uses points of interest data from digital mapping company TomTom. Tesla is also one of several automakers that has its own navigation software on a closed OS but uses Places API for mapping data.\nHowever, Hyundai, Kia, and Genesis will soon follow the industry-wide trend of moving to Google’s Android...\nRead the full story at The Verge.",
    "author": "Umar Shakir"
  },
  {
    "title": "YouTube TV’s monthly cost soars to $82.99",
    "link": "https://www.theverge.com/2024/12/12/24319585/youtube-tv-2024-subscription-price-increase-82-99",
    "pubDate": "2024-12-12T15:43:33.000Z",
    "content": "  \n\n    <figure>\n      <img alt=\"YouTube logo image in red over a geometric red, black, and cream background\" src=\"https://cdn.vox-cdn.com/thumbor/ImLo1T1QyFuYB219TiQky1HxN1E=/0x0:2040x1360/1310x873/cdn.vox-cdn.com/uploads/chorus_image/image/73782568/acastro_STK092_03.0.jpg\" />\n        <figcaption>Illustration by Alex Castro / The Verge</figcaption>\n    </figure>\n\n  <p id=\"sigfN0\">I maintain that YouTube TV is the very best of the streaming TV services, but good grief is it getting expensive. Today <a href=\"https://support.google.com/youtubetv/answer/9285852\">YouTube announced</a> the service’s latest price hike, which brings the monthly subscription to $82.99. The change is effective immediately for new customers and will be reflected starting January 13th for “most existing customers.” As usual, the company attributes this increase to “the rising cost of content and the investments we make in the quality of our service.”</p>\n<p id=\"0OOGrX\">$82.99 is the <a href=\"https://go.redirectingat.com?id=66960X1514734&amp;xs=1&amp;url=https%3A%2F%2Fwww.hulu.com%2Flive-tv&amp;referrer=theverge.com&amp;sref=https%3A%2F%2Fwww.theverge.com%2F2024%2F12%2F12%2F24319585%2Fyoutube-tv-2024-subscription-price-increase-82-99\" rel=\"sponsored nofollow noopener\" target=\"_blank\">same price</a> as Disney’s Hulu + Live TV bundle.</p>\n<p id=\"L7bkI3\">YouTube TV last raised its subscription cost <a href=\"https://www.theverge.com/2023/3/16/23643448/youtube-tv-price-increase-8-cable-pricing\">to $72.99</a> in March 2023. Before that, it was $64.99. The days when the service <a href=\"https://www.theverge.com/2019/4/10/18304871/youtube-tv-april-2019-price-increase-discovery-hgtv\">ran only $50</a> now feel like a lifetime ago. Some of you who got in early might even remember it costing a mere <a href=\"https://www.theverge.com/2018/3/12/17109018/youtube-tv-price-change-signup-grandfathered-google\">$35 per month</a>. </p>\n<p id=\"nbNtAA\">But since then, YouTube has routinely found itself in carriage disputes with Disney, NBCUniversal, and other content owners, and those renegotiated agreements have led YouTube TV’s price to climb higher and higher. The YouTube TV of today is much different than it used to be; there are more channels, yes, but the service has also shed a number of regional sports networks. </p>\n<p id=\"IulDt5\">The company is quick to note that none of the service’s core benefits are changing. The base subscription still includes over 100 channels, cloud DVR with unlimited storage, up to six user accounts per household, and the flexibility of three concurrent streams. But YouTube TV still charges extra for 4K streaming, which seems harder to rationalize after this $10 price bump. </p>\n<p id=\"uo9VoT\"><a href=\"https://www.reddit.com/r/youtubetv/comments/1hclr76/mega_thread_youtube_tv_raises_monthly_base_plan/\">Customers are predictably none too pleased</a> about the news and are weighing whether a service that now costs more than double its original price is still worth it. </p>\n\n",
    "summary": "Illustration by Alex Castro / The Verge\n    \n\n  \nI maintain that YouTube TV is the very best of the streaming TV services, but good grief is it getting expensive. Today YouTube announced the service’s latest price hike, which brings the monthly subscription to $82.99. The change is effective immediately for new customers and will be reflected starting January 13th for “most existing customers.” As usual, the company attributes this increase to “the rising cost of content and the investments we make in the quality of our service.”\n$82.99 is the same price as Disney’s Hulu + Live TV bundle.\nYouTube TV last raised its subscription cost to $72.99 in March 2023. Before that, it was $64.99. The days when the service ran only $50 now feel like a lifetime ago. Some of you who got in early might even remember it costing a mere $35 per month. \nBut since then, YouTube has routinely found itself in carriage disputes with Disney, NBCUniversal, and other content owners, and those renegotiated agreements have led YouTube TV’s price to climb higher and higher. The YouTube TV of today is much different than it used to be; there are more channels, yes, but the service has also shed a number of regional sports networks. \nThe company is quick to note that none of the service’s core benefits are changing. The base subscription still includes over 100 channels, cloud DVR with unlimited storage, up to six user accounts per household, and the flexibility of three concurrent streams. But YouTube TV still charges extra for 4K streaming, which seems harder to rationalize after this $10 price bump. \nCustomers are predictably none too pleased about the news and are weighing whether a service that now costs more than double its original price is still worth it.",
    "author": "Chris Welch"
  },
  {
    "title": "Sora’s AI video revolution is still a ways off",
    "link": "https://www.theverge.com/2024/12/12/24318924/openai-sora-ai-video-generator-hands-on",
    "pubDate": "2024-12-12T15:30:00.000Z",
    "content": "  \n\n    <figure>\n      <img alt=\"A screenshot taken from an AI-generated video showing a woman eating a pastry.\" src=\"https://cdn.vox-cdn.com/thumbor/wn2l4IMwyMmSIqCFStL-KB7YnW8=/0x127:1870x1374/1310x873/cdn.vox-cdn.com/uploads/chorus_image/image/73782551/Sora_AI_sausage_roll_eating.0.png\" />\n        <figcaption><em>Prompt: “King Charles III UK eating a Greggs sausage roll on the throne.” There’s a lot wrong with these results...</em> | Image: OpenAI / The Verge</figcaption>\n    </figure>\n\n  <p id=\"ipT80z\">The first version of OpenAI’s Sora can generate video of just about anything you throw at it — superheroes, cityscapes, animated puppies. It’s an impressive first step for the AI video generator. But the actual results are far from satisfactory, with many videos so heavily plagued with oddities and inconsistencies that it’s hard to imagine anyone finding much use for them.</p>\n<p id=\"g32pAR\">Sora <a href=\"https://www.theverge.com/2024/12/9/24317092/openai-sora-text-to-video-ai-launch\">was released on Monday</a> after <a href=\"https://www.theverge.com/2024/2/15/24074151/openai-sora-text-to-video-ai\">almost a year of teasers</a> heralding its capabilities. There are a few hurdles before you get to the video generation features, though. For one, <a href=\"https://www.theverge.com/2024/12/10/24317856/openai-closed-sora-applications-shortly-after-launch\">account creation was closed</a> within hours of launching due to the overwhelming demand. Those who did manage to sign up will find that its features also require a subscription to unlock: a $20 monthly “Plus” membership will let you generate videos at 480p or 720p, capped at either five or 10 seconds in length depending on the resolution. To unlock everything, including 1080p quality and 20-second-long videos, you need to cough up $200 a month for the “Pro” Sora subscription.</p>\n<div id=\"053DBv\">\n<!--  ########  BEGIN VOLUME VIDEO  ########  --><div data-analytics-viewport=\"video\" data-analytics-action=\"volume:view:article:middle\" data-analytics-label=\"Sora cat podcast|118705\" data-volume-uuid=\"2988c2126\" data-volume-id=\"118705\" data-analytics-placement=\"article:middle\" data-volume-placement=\"article\" data-volume-autoplay=\"false\" id=\"volume-placement-797\" class=\"volume-video\"></div>\n<!--  ########  END VOLUME VIDEO  ########  --><div class=\"caption\">\n<em>Prompt: “An indigo-colored cat lounging on a green armchair while wearing a pair of wireless headphones. A smartphone beside it is playing the </em>Vergecast<em> podcast.”</em>\n</div>\n...</div>\n  <p><a href=\"https://www.theverge.com/2024/12/12/24318924/openai-sora-ai-video-generator-hands-on\">Read the full story at The Verge.</a></p>\n\n",
    "summary": "Prompt: “King Charles III UK eating a Greggs sausage roll on the throne.” There’s a lot wrong with these results... | Image: OpenAI / The Verge\n    \n\n  \nThe first version of OpenAI’s Sora can generate video of just about anything you throw at it — superheroes, cityscapes, animated puppies. It’s an impressive first step for the AI video generator. But the actual results are far from satisfactory, with many videos so heavily plagued with oddities and inconsistencies that it’s hard to imagine anyone finding much use for them.\nSora was released on Monday after almost a year of teasers heralding its capabilities. There are a few hurdles before you get to the video generation features, though. For one, account creation was closed within hours of launching due to the overwhelming demand. Those who did manage to sign up will find that its features also require a subscription to unlock: a $20 monthly “Plus” membership will let you generate videos at 480p or 720p, capped at either five or 10 seconds in length depending on the resolution. To unlock everything, including 1080p quality and 20-second-long videos, you need to cough up $200 a month for the “Pro” Sora subscription.\n\n\nPrompt: “An indigo-colored cat lounging on a green armchair while wearing a pair of wireless headphones. A smartphone beside it is playing the Vergecast podcast.”\n\n...\nRead the full story at The Verge.",
    "author": "Jess Weatherbed"
  }
]