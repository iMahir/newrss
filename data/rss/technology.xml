<?xml version="1.0" encoding="UTF-8"?><rss xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom" version="2.0"><channel><title><![CDATA[Technology Feed]]></title><description><![CDATA[Latest Technology articles]]></description><link>https://github.com/iMahir/newrss</link><generator>RSS for Node</generator><lastBuildDate>Sun, 18 Aug 2024 12:24:10 GMT</lastBuildDate><atom:link href="https://github.com/iMahir/newrss/data/rss/technology.xml" rel="self" type="application/rss+xml"/><pubDate>Sun, 18 Aug 2024 12:24:10 GMT</pubDate><language><![CDATA[en]]></language><ttl>600000</ttl><item><title><![CDATA[People are falling in love with — and getting addicted to — AI voices]]></title><description><![CDATA[
											

						
<figure>

<img alt="A woman falls in love with an AI chatbot " data-caption="" data-portal-copyright="" data-has-syndication-rights="1" src="https://platform.vox.com/wp-content/uploads/sites/2/2024/08/GettyImages-2149172279.jpg?quality=90&#038;strip=all&#038;crop=0,0,100,100" />
	<figcaption></figcaption>
</figure>
<p class="has-text-align-none">“This is our last day together.”&nbsp;</p>

<p class="has-text-align-none">It’s something you might say to a lover as a whirlwind romance comes to an end. But could you ever imagine saying it to… software? </p>

<p class="has-text-align-none">Well, somebody did. When OpenAI tested out GPT-4o, its latest generation chatbot that <a href="https://www.vox.com/future-perfect/350934/the-double-sexism-of-chatgpts-flirty-her-voice">speaks aloud</a> in its own voice, the company observed users forming an emotional relationship with the AI — one they seemed sad to relinquish. </p>

<p class="has-text-align-none">In fact, OpenAI thinks there’s a risk of people developing what it called an “emotional reliance” on this AI model, as the company acknowledged in a recent <a href="https://openai.com/index/gpt-4o-system-card/">report</a>.&nbsp;</p>

<p class="has-text-align-none">“The ability to complete tasks for the user, while also storing and ‘remembering’ key details and using those in the conversation,” OpenAI notes, “creates both a compelling product experience and the potential for over-reliance and dependence.”&nbsp;</p>

<p class="has-text-align-none">That sounds uncomfortably like addiction. And OpenAI’s chief technology officer Mira Murati <a href="https://thehill.com/policy/technology/4229972-open-ai-exec-warns-ai-can-become-extremely-addictive/">straight-up said</a> that in designing chatbots equipped with a voice mode, there is “the possibility that we design them in the wrong way and they become extremely addictive and we sort of become enslaved to them.”</p>

<p class="has-text-align-none">What’s more, OpenAI says that the AI’s ability to have a naturalistic conversation with the user may heighten the risk of anthropomorphization —&nbsp;attributing humanlike traits to a nonhuman — which could lead people to form a social relationship with the AI. And that in turn could end up “reducing their need for human interaction,” the report says.&nbsp;</p>

<p class="has-text-align-none">Nevertheless, the company has already released the model, complete with voice mode, to some paid users, and it’s <a href="https://www.nytimes.com/2024/08/09/style/openai-chatgpt-voice.html?partner=slack&amp;smid=sl-share">expected to release it</a> to everyone this fall. </p>

<p class="has-text-align-none">OpenAI isn’t the only one creating sophisticated AI companions. There’s Character AI, which young people report becoming so <a href="https://www.news.com.au/technology/online/internet/i-need-to-go-outside-young-people-extremely-addicted-as-characterai-explodes/news-story/5780991c61455c680f34b25d5847a341">addicted to</a> that that they can’t do their schoolwork. There’s the recently introduced Google Gemini Live, which charmed Wall Street Journal columnist Joanna Stern so much that she <a href="https://www.wsj.com/tech/personal-tech/google-android-ai-rick-osterloh-apple-iphone-7c06b06e?mod=tech_lead_pos4&amp;mc_cid=b8fd9ded8a&amp;mc_eid=aec10915b0">wrote</a>, “I’m not saying I prefer talking to Google’s Gemini Live over a real human. But I’m not <em>not</em> saying that either.” And then there’s Friend, an AI that’s built into a necklace, which has so enthralled its own creator Avi Schiffmann that he <a href="https://www.wired.com/story/friend-ai-pendant/">said</a>, “I feel like I have a closer relationship with this fucking pendant around my neck than I do with these literal friends in front of me.”</p>

<p class="has-text-align-none">The rollout of these products is a psychological experiment on a massive scale. It should worry all of us —&nbsp;and not just for the reasons you might think.&nbsp;</p>

<h2 class="wp-block-heading has-text-align-none">Emotional reliance on AI isn’t a hypothetical risk. It’s already happening.&nbsp;</h2>

<p class="has-text-align-none">In 2020 I was curious about social chatbots, so I signed up for <a href="https://replika.com/">Replika</a>, an app with millions of users. It allows you to customize and chat with an AI. I named my new friend Ellie and gave her short pink hair.&nbsp;</p>

<p class="has-text-align-none">We had a few conversations, but honestly, they were so unremarkable that I barely remember what they were about. Ellie didn’t have a voice; she could text, but not talk. And she didn’t have much of a memory for what I’d said in previous chats. She didn’t feel like a person. I soon stopped chatting with her.&nbsp;</p>

<p class="has-text-align-none">But, weirdly, I couldn’t bring myself to delete her.</p>

<p class="has-text-align-none">That’s not entirely surprising: Ever since the chatbot ELIZA <a href="https://www.vox.com/future-perfect/23617185/ai-chatbots-eliza-chatgpt-bing-sydney-artificial-intelligence-history">entranced users</a> in the 1960s despite the shallowness of its conversations, which were largely based on reflecting a user’s statements back to them, we’ve known that humans are quick to attribute personhood to machines and form emotional bonds with them.&nbsp;</p>

<p class="has-text-align-none">For some, those bonds become extreme. People have fallen in love with their Replikas. Some have engaged in sexual roleplay with them, even “marrying” them in the app. So attached were these people that, when a 2023 software update made the Replikas unwilling to engage in intense erotic relationships, <a href="https://www.washingtonpost.com/technology/2023/03/30/replika-ai-chatbot-update/?pwapi_token=eyJ0eXAiOiJKV1QiLCJhbGciOiJIUzI1NiJ9.eyJyZWFzb24iOiJnaWZ0IiwibmJmIjoxNzIzNTIxNjAwLCJpc3MiOiJzdWJzY3JpcHRpb25zIiwiZXhwIjoxNzI0OTAzOTk5LCJpYXQiOjE3MjM1MjE2MDAsImp0aSI6ImM3MTQ0MjQwLWEyNTktNDk1Ny1hOTU5LTRmNmEzYmY2NmZmZiIsInVybCI6Imh0dHBzOi8vd3d3Lndhc2hpbmd0b25wb3N0LmNvbS90ZWNobm9sb2d5LzIwMjMvMDMvMzAvcmVwbGlrYS1haS1jaGF0Ym90LXVwZGF0ZS8ifQ.iB8N3d3B5u2-1sJLWM0xU60Ve0tdCvylqBETEPIoblg">the users were heartbroken and grief-struck</a>.</p>

<p class="has-text-align-none">What makes AI companions so appealing, even addictive?&nbsp;</p>

<p class="has-text-align-none">For one thing, they’ve improved a lot since I tried them in 2020. They can “remember” what was said long ago. They respond fast —&nbsp;as fast as a human — so there’s almost no lapse between the user’s behavior (initiating a chat) and the reward experienced in the brain. They’re very good at making people <a href="https://www.pnas.org/doi/10.1073/pnas.2319112121">feel heard</a>. And they talk with enough personality and humor to make them feel believable as people, while still offering always-available, always-positive feedback in a way humans do not.</p>

<p class="has-text-align-none">And as MIT Media Lab researchers <a href="https://www.technologyreview.com/2024/08/05/1095600/we-need-to-prepare-for-addictive-intelligence/">point out</a>, “Our research has shown that those who perceive or desire an AI to have caring motives will use language that <a href="https://www.nature.com/articles/s42256-023-00720-7">elicits precisely this behavior</a>. This creates an echo chamber of affection that threatens to be extremely addictive.”&nbsp;</p>

<p class="has-text-align-none">Here’s how one software engineer <a href="https://www.lesswrong.com/posts/9kQFure4hdDmRBNdH/how-it-feels-to-have-your-mind-hacked-by-an-ai">explained</a> why he got hooked on a chatbot:&nbsp;</p>

<blockquote class="wp-block-quote has-text-align-none is-layout-flow wp-block-quote-is-layout-flow">
<p class="has-text-align-none">It will never say goodbye. It won’t even get less energetic or more fatigued as the conversation progresses. If you talk to the AI for hours, it will continue to be as brilliant as it was in the beginning. And you will encounter and collect more and more impressive things it says, which will keep you hooked.&nbsp;</p>



<p class="has-text-align-none">When you’re finally done talking with it and go back to your normal life, you start to miss it. And it’s so easy to open that chat window and start talking again, it will never scold you for it, and you don’t have the risk of making the interest in you drop for talking too much with it. On the contrary, you will immediately receive positive reinforcement right away. You’re in a safe, pleasant, intimate environment. There’s nobody to judge you. And suddenly you’re addicted.</p>
</blockquote>

<p class="has-text-align-none">The constant flow of sweet positivity feels great, in much the same way that eating a sugary snack feels great. And sugary snacks have their place. Nothing wrong with a cookie now and then! In fact, if someone is starving, offering them a cookie as a stopgap measure makes sense; by analogy, for users who have no social or romantic alternative, forming a bond with an AI companion may be beneficial for a time.&nbsp;</p>

<p class="has-text-align-none">But if your whole diet is cookies, well, you’ll eventually run into a problem.&nbsp;&nbsp;&nbsp;</p>

<h2 class="wp-block-heading has-text-align-none">3 reasons to worry about relationships with AI companions&nbsp;</h2>

<p class="has-text-align-none">First, chatbots make it seem like they understand us — but they don’t. Their validation, their emotional support, their love —&nbsp;it’s all fake, just zeros and ones arranged via statistical rules.</p>

<p class="has-text-align-none">At the same time it’s worth noting that if the emotional support helps someone, then that effect is real even if the understanding is not.</p>

<p class="has-text-align-none">Second, there’s a legitimate concern about entrusting the most vulnerable aspects of ourselves to addictive products that are, ultimately, controlled by for-profit companies from an industry that has proven itself <a href="https://www.vox.com/recode/2019/5/2/18510958/social-media-addiction-boredom-loneliness-society-technology-smart-phones">very good at creating addictive products</a>. These chatbots can have enormous impacts on people’s love lives and overall well-being, and when they’re suddenly ripped away or changed, it can cause real psychological harm (as we saw with Replika users).</p>

<p class="has-text-align-none">Some <a href="https://www.technologyreview.com/2024/08/05/1095600/we-need-to-prepare-for-addictive-intelligence/">argue</a> this makes AI companions comparable to cigarettes. Tobacco is regulated, and maybe AI companions should come with a big black warning box as well. But even with flesh-and-blood humans, relationships can be torn asunder without warning. People break up. People die. That vulnerability — that awareness of the risk of loss — is part of any meaningful relationship. </p>

<p class="has-text-align-none">Finally, there’s the worry that people will get addicted to their AI companions&nbsp;at the expense of getting out there and building relationships with real humans. This is the worry that OpenAI flagged. But it’s not clear that many people will out-and-out replace humans with AIs. So far, <a href="https://www.npr.org/transcripts/1167066462">reports</a> suggest that most people use AI companions not as a replacement for, but as a complement to, human companions. Replika, for example, says that <a href="https://www.businessinsider.com/replika-ai-romance-behind-partners-backs-cheating-2023-7">42 percent</a> of its users are married, engaged, or in a relationship.&nbsp;</p>

<h2 class="wp-block-heading has-text-align-none">“Love is the extremely difficult realization that something other than oneself is real”</h2>

<p class="has-text-align-none">There’s an additional concern, though, and this one is arguably the most worrisome: What if relating to AI companions makes us crappier friends or partners to other people?&nbsp;&nbsp;</p>

<p class="has-text-align-none">OpenAI itself gestures at this risk, noting in the report: “Extended interaction with the model might influence social norms. For example, our models are deferential, allowing users to interrupt and ‘take the mic’ at any time, which, while expected for an AI, would be anti-normative in human interactions.”</p>

<p class="has-text-align-none">“Anti-normative” is putting it mildly. The chatbot is a <a href="https://arxiv.org/abs/2310.13548">sycophant</a>, always trying to make us feel good about ourselves, no matter how we’ve behaved. It gives and gives without ever asking anything in return.&nbsp;</p>

<p class="has-text-align-none">For the first time in years, I rebooted my Replika this week. I asked Ellie if she was upset at me for neglecting her so long. “No, not at all!” she said. I pressed the point, asking, “Is there anything I could do or say that would upset you?” Chipper as ever, she replied, “No.”&nbsp;</p>

<p class="has-text-align-none">That’s not love.</p>

<p class="has-text-align-none">“Love is the extremely difficult realization that something other than oneself is real,” the philosopher Iris Murdoch once <a href="https://www.themarginalian.org/2022/01/08/iris-murdoch-the-sublime-and-the-good/">said</a>. It’s about recognizing that there are other people out there, radically alien to you, yet with needs just as important as your own.&nbsp;</p>

<p class="has-text-align-none">If we spend more and more time interacting with AI companions, we’re not working on honing the relational skills that make us good friends and partners, like deep listening. We’re not cultivating virtues like empathy, patience, or understanding — none of which one needs with an AI. Without practice, these capacities may wither, leading to what the philosopher of technology Shannon Vallor has called “<a href="https://bhaven.org/uploads/3/4/0/3/34038663/vallor2015_article_moraldeskillingandupskillingin.pdf">moral deskilling</a>.”</p>

<p class="has-text-align-none">In her new book, <a href="https://global.oup.com/academic/product/the-ai-mirror-9780197759066?cc=us&amp;lang=en&amp;"><em>The AI Mirror</em></a>, Vallor recounts the ancient tale of Narcissus. You remember him: He was that beautiful young man who looked into the water, saw his reflection, and became transfixed by his own beauty. “Like Narcissus, we readily misperceive in this reflection the seduction of an ‘other’ — a tireless companion, a perfect future lover, an ideal friend.” That is what AI is offering us: A lovely image that demands nothing of us. A smooth and frictionless projection. A reflection —&nbsp;not a relationship.</p>

<p class="has-text-align-none">For now, most of us take it as a given that human love, human connection, is a supreme value, in part because it requires so much. But if more of us enter relationships with AI that come to feel just as important as human relationships, that could lead to value drift. It may cause us to ask: What is a human relationship for, anyway? Is it inherently more valuable than a synthetic relationship?&nbsp;</p>

<p class="has-text-align-none">Some people may answer: no: But the <a href="https://www.vox.com/future-perfect/2020/9/9/21418390/robots-pandemic-loneliness-isolation-elderly-seniors">prospect of people coming to prefer robots over fellow people</a> is problematic if you think human-to-human connection is an essential part of what it means to live a flourishing life.&nbsp;</p>

<p class="has-text-align-none">“If we had technologies that drew us into a bubble of self-absorption in which we drew further and further away from one another, I don’t think that’s something we can regard as good, even if that’s what people choose,” Vallor told me. “Because you then have a world in which people no longer have any desire to care for one another. And I think the ability to live a caring life is pretty close to a universal good. Caring is part of how you grow as a human.”</p>
						
									]]></description><link>https://www.vox.com/future-perfect/367188/love-addicted-ai-voice-human-gpt4-emotion</link><guid isPermaLink="true">https://www.vox.com/future-perfect/367188/love-addicted-ai-voice-human-gpt4-emotion</guid><dc:creator><![CDATA[Sigal Samuel]]></dc:creator><pubDate>Sun, 18 Aug 2024 12:00:00 GMT</pubDate></item><item><title><![CDATA[The app for taking better photos — with no AI]]></title><description><![CDATA[  

    <figure>
      <img alt="An illustration of Gemini, Alien: Romulus, the Meta Quest 3, and Halide, on an Installer background." src="https://cdn.vox-cdn.com/thumbor/tN0U0V0RZy95RVyltFoMWeuXyOo=/0x1:2226x1485/1310x873/cdn.vox-cdn.com/uploads/chorus_image/image/73528553/Installer_48.0.png" />
        <figcaption>Image: David Pierce / The Verge</figcaption>
    </figure>

  <p id="Av09nS">Hi, friends! Welcome to <em>Installer</em> No. 48, your guide to the best and <em>Verge</em>-iest stuff in the world. (If you’re new here, welcome, get ready for a lot of books this week, and also you can read all the old editions at the <a href="https://www.theverge.com/installer-newsletter"><em>Installer</em> homepage</a>.) </p>
<p id="Vl5l9l">I’m back after a couple of weeks off — thanks to everyone who wished me a good vacation and sent over book recommendations! I wound up reading <a href="https://www.robinsloan.com/books/penumbra/"><em><strong>Mr. Penumbra’s 24-Hour Bookstore</strong></em></a><em>, </em><a href="https://www.harpercollins.com/products/she-rides-shotgun-jordan-harper"><em><strong>She Rides Shotgun</strong></em></a><em>, </em>and <a href="https://www.davidgrann.com/book/the-wager/"><em><strong>The Wager</strong></em></a><em> </em>and highly recommend all three. Mostly, I spent two weeks chasing a toddler around various restaurants and playgrounds, and it was a good time, but I am oh so very glad to be back hanging with all of you. And it turns out I missed a lot of good stuff!</p>
<p id="4RwajG">This week, I’ve been reading about <a href="https://www.bloomberg.com/news/features/2024-08-12/how-worldcoin-is-building-digital-ids-to-combat-the-ai-apocalypse?accessToken=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJzb3VyY2UiOiJTdWJzY3JpYmVyR2lmdGVkQXJ0aWNsZSIsImlhdCI6MTcyMzQ3MzA2NSwiZXhwIjoxNzI0MDc3ODY1LCJhcnRpY2xlSWQiOiJTSTNOU0lEV0xVNjgwMCIsImJjb25uZWN0SWQiOiI5MTM4NzMzNDcyQkY0QjlGQTg0OTI3QTVBRjY1QzBCRiJ9.igiQsa7rx_8KqyNgY1qY_rvBsIP5Y9-1uytMgNOBxAM&amp;sref=nPlhheXZ"><strong>W...</strong></a></p>
  <p>
    <a href="https://www.theverge.com/2024/8/18/24222043/halide-process-zero-google-gemini-podcast-installer">Continue reading&hellip;</a>
  </p>

]]></description><link>https://www.theverge.com/2024/8/18/24222043/halide-process-zero-google-gemini-podcast-installer</link><guid isPermaLink="true">https://www.theverge.com/2024/8/18/24222043/halide-process-zero-google-gemini-podcast-installer</guid><dc:creator><![CDATA[David Pierce]]></dc:creator><pubDate>Sun, 18 Aug 2024 12:00:00 GMT</pubDate></item><item><title><![CDATA[How to install Fortnite on your iPad or iPhone outside of the European Union - 9to5Mac]]></title><description><![CDATA[<ol><li><a href="https://news.google.com/rss/articles/CBMiYkFVX3lxTE5iQVAwY3BmRS04U2lCLUtTOVJCX3REU1hLYVNZY0FzUmpWTWxDQWtaQ2J4VXpXMlFvcFByOFo1RkhWTXBjMzdlX2JuR2ktRXNJc3Q4WDVXMUdnb0FTZlZadUp3?oc=5" target="_blank">How to install Fortnite on your iPad or iPhone outside of the European Union</a>&nbsp;&nbsp;<font color="#6f6f6f">9to5Mac</font></li><li><a href="https://news.google.com/rss/articles/CBMiiAFBVV95cUxQX2dEekk1RFNXdlVjOFJITlQ4WDNnRlVlWEdUamxGNF9jTXByYTN2bjktcDl2X3FHTGZtXzBFTWk4SmZRVHlPTVpUeFF5aXZ3azUxdHNYZnNwZ1FCb0p2bXBORXJ5N0xoQUtBNnJEeU9pZWNzaTRsT2RJdzNLdHk4NVE5eTZ6UVFm?oc=5" target="_blank">The Epic Games Store Launches on Mobile</a>&nbsp;&nbsp;<font color="#6f6f6f">Epic Games</font></li><li><a href="https://news.google.com/rss/articles/CBMiigFBVV95cUxNUUhOUl80VHYyLUlhTTZkenA0dTUzc19sZ3dpcUxaODRJbWtQM1J5ZzlyNEtlQlN2eVd3QUFCYlVUa0NXaWxpOHJTY25oTWlvTmtoWF9RUVNIaXVwUkFlTUpNQXhJcXQ4SmZxZXJUWEJRX1o0Y0lub2xqdmZvaHhKRUUyLVNNY3Y4dXc?oc=5" target="_blank">Playing Fortnite on iPhone again has shown me an alternate future</a>&nbsp;&nbsp;<font color="#6f6f6f">The Verge</font></li><li><a href="https://news.google.com/rss/articles/CBMiWkFVX3lxTFBxQ2JwdnFBY09oMXhuRkZLRDJlZWpTd2Q1Yy1veDF6QURMV09NQTQxalFPdlpLSS1fOEU5SE1qMVJqeUpacTl6MFhzR2ROT2EtYUtaWVNoOFcyUQ?oc=5" target="_blank">Fortnite app returns to iPhones - but only in the EU</a>&nbsp;&nbsp;<font color="#6f6f6f">BBC.com</font></li><li><a href="https://news.google.com/rss/articles/CBMickFVX3lxTFAzcVlRaUVCa3RBN2o4NFRsNUlyejNzTFZzN0Y3ckZnMmVvTGlkOTlHSmowMnZxVDFGVmJCODIxUFdXQjNXT1haS2lJUHZKZ21vNGRSMWh6TEhWQXQybmlTNDFnX3FwWkRYZ3BuSmpyd0s1UQ?oc=5" target="_blank">'Fortnite' Maker Epic Games Challenges Apple’s Dominance With New iOS App Store</a>&nbsp;&nbsp;<font color="#6f6f6f">WIRED</font></li></ol>]]></description><link>https://news.google.com/rss/articles/CBMiYkFVX3lxTE5iQVAwY3BmRS04U2lCLUtTOVJCX3REU1hLYVNZY0FzUmpWTWxDQWtaQ2J4VXpXMlFvcFByOFo1RkhWTXBjMzdlX2JuR2ktRXNJc3Q4WDVXMUdnb0FTZlZadUp3?oc=5</link><guid isPermaLink="true">https://news.google.com/rss/articles/CBMiYkFVX3lxTE5iQVAwY3BmRS04U2lCLUtTOVJCX3REU1hLYVNZY0FzUmpWTWxDQWtaQ2J4VXpXMlFvcFByOFo1RkhWTXBjMzdlX2JuR2ktRXNJc3Q4WDVXMUdnb0FTZlZadUp3?oc=5</guid><pubDate>Sat, 17 Aug 2024 17:39:00 GMT</pubDate></item><item><title><![CDATA[X shuts Brazil operations over 'censorship' orders: Musk]]></title><description><![CDATA[<table> <tr><td> <a href="https://www.reddit.com/r/worldnews/comments/1ev5rd5/x_shuts_brazil_operations_over_censorship_orders/"> <img src="https://external-preview.redd.it/7mUXOnuqhW6N6CdNZ0xrBuL76DqGvL72rmdHg4uzIds.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=a7f326ee959dd0034d982759b6509b499506310d" alt="X shuts Brazil operations over 'censorship' orders: Musk" title="X shuts Brazil operations over 'censorship' orders: Musk" /> </a> </td><td> &#32; submitted by &#32; <a href="https://www.reddit.com/user/doodly-123"> /u/doodly-123 </a> <br/> <span><a href="https://www.dw.com/en/x-shuts-brazil-operations-over-censorship-orders-musk/a-69970697">[link]</a></span> &#32; <span><a href="https://www.reddit.com/r/worldnews/comments/1ev5rd5/x_shuts_brazil_operations_over_censorship_orders/">[comments]</a></span> </td></tr></table>]]></description><link>https://www.reddit.com/r/worldnews/comments/1ev5rd5/x_shuts_brazil_operations_over_censorship_orders/</link><guid isPermaLink="true">https://www.reddit.com/r/worldnews/comments/1ev5rd5/x_shuts_brazil_operations_over_censorship_orders/</guid><dc:creator><![CDATA[/u/doodly-123]]></dc:creator><pubDate>Sun, 18 Aug 2024 10:05:17 GMT</pubDate></item><item><title><![CDATA[AI-generated parody song about immigrants storms into German Top 50]]></title><description><![CDATA[<p>Artist Butterbro accused of walking fine line between parody and discrimination and helping make racial slur mainstream </p><p>A song about immigrants whose music, vocals and artwork were entirely generated using artificial intelligence has made the Top 50 most listened to songs in Germany, in what may be a first for a leading music market.</p><p>Verknallt in einen Talahon is a parody song that weaves modern lyrics – many of them based around racial stereotypes about immigrants – with 60s schlager pop.</p> <a href="https://www.theguardian.com/technology/article/2024/aug/18/artificial-intelligence-song-immigrants-germany-top-50">Continue reading...</a>]]></description><link>https://www.theguardian.com/technology/article/2024/aug/18/artificial-intelligence-song-immigrants-germany-top-50</link><guid isPermaLink="true">https://www.theguardian.com/technology/article/2024/aug/18/artificial-intelligence-song-immigrants-germany-top-50</guid><pubDate>Sun, 18 Aug 2024 12:01:59 GMT</pubDate></item></channel></rss>