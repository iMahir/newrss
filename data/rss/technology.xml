<?xml version="1.0" encoding="UTF-8"?><rss xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom" version="2.0"><channel><title><![CDATA[Technology Feed]]></title><description><![CDATA[Latest Technology articles]]></description><link>https://github.com/iMahir/newrss</link><generator>RSS for Node</generator><lastBuildDate>Wed, 11 Dec 2024 15:46:32 GMT</lastBuildDate><atom:link href="https://github.com/iMahir/newrss/data/rss/technology.xml" rel="self" type="application/rss+xml"/><pubDate>Wed, 11 Dec 2024 15:46:32 GMT</pubDate><language><![CDATA[en]]></language><ttl>600000</ttl><item><title><![CDATA[Google’s AI enters its ‘agentic era’]]></title><description><![CDATA[  

    <figure>
      <img alt="A woman holding a phone, and to the right, her phone is overlayed and displayed. On the phone, she’s recording her surroundings with Google’s AI product, Project Astra." src="https://cdn.vox-cdn.com/thumbor/HGvl11UuqpE8qjquvo5ZJP25Hx4=/363x6:1920x1044/1310x873/cdn.vox-cdn.com/uploads/chorus_image/image/73780393/TT_ASH_STILL_FINAL.0.jpeg" />
        <figcaption>Image: Google</figcaption>
    </figure>

  <p id="yh0QVL">I stepped into a room lined with bookshelves, stacked with ordinary programming and architecture texts. One shelf stood slightly askew, and behind it was a hidden room that had three TVs displaying famous artworks: Edvard Munch’s <a href="https://www.edvardmunch.org/the-scream.jsp"><em>The Scream</em></a>, Georges Seurat’s <a href="https://www.artic.edu/artworks/27992/a-sunday-on-la-grande-jatte-1884"><em>Sunday Afternoon</em></a>, and Hokusai’s <a href="https://en.wikipedia.org/wiki/The_Great_Wave_off_Kanagawa"><em>The Great Wave off Kanagawa</em></a>. “There’s some interesting pieces of art here,” said Bibo Xu, Google DeepMind’s lead product manager for Project Astra. “Is there one in particular that you would want to talk about?” </p>
<p id="JtPKZx">Project Astra, Google’s prototype AI “universal agent,” responded smoothly. “The <em>Sunday Afternoon </em>artwork was discussed previously,” it replied. “Was there a particular detail about it you wish to discuss, or were you interested in discussing <em>The Scream</em>?”</p>
<p id="mkgXk5">I was at Google’s sprawling Mountain View campus, seeing the latest projects from its AI lab DeepMind. One was Project Astra, a virtual assistant <a href="https://www.theverge.com/2024/5/14/24156296/google-ai-gemini-astra-assistant-live-io">first demoed at Google I/O</a> earlier this year. Currently contained in an app, it can process text, images, video, and audio in real time and respond to questions about them. It’s like a Siri or Alexa that’s slightly more natural to talk to, can see the world around you, and can “remember”...</p>
  <p><a href="https://www.theverge.com/2024/12/11/24317436/google-deepmind-project-astra-mariner-ai-agent">Read the full story at The Verge.</a></p>

]]></description><link>https://www.theverge.com/2024/12/11/24317436/google-deepmind-project-astra-mariner-ai-agent</link><guid isPermaLink="true">https://www.theverge.com/2024/12/11/24317436/google-deepmind-project-astra-mariner-ai-agent</guid><dc:creator><![CDATA[Kylie Robison]]></dc:creator><pubDate>Wed, 11 Dec 2024 15:33:02 GMT</pubDate></item><item><title><![CDATA[It sure sounds like Google is planning to actually launch some smart glasses]]></title><description><![CDATA[  

    <figure>
      <img alt="A man in a bike helmet, wearing glasses." src="https://cdn.vox-cdn.com/thumbor/QZUN81v654TmFeyekOgmYrAdLMc=/70x0:1690x1080/1310x873/cdn.vox-cdn.com/uploads/chorus_image/image/73780383/Google_Glasses.0.png" />
        <figcaption><em>Here’s what Google’s latest smart glasses prototype looks like.</em> | Image: Google</figcaption>
    </figure>

  <p id="9peXhl">Google is working on a lot of AI stuff — like, a <em>lot </em>of AI stuff — but if you want to really understand the company’s vision for virtual assistants, take a look at Project Astra. Google first showed a demo of its all-encompassing, multimodal virtual assistant at Google I/O this spring and clearly imagines Astra as an always-on helper in your life. In reality, the tech is somewhere between “neat concept video” and “early prototype,” but it represents the most ambitious version of Google’s AI work. </p>
<p id="gFgV3p">And there’s one thing that keeps popping up in Astra demos: glasses. Google has been working on smart facewear of one kind or another for years, from Glass to Cardboard to the <a href="https://www.theverge.com/2022/7/19/23270219/google-ar-prototypes-test-public">Project Iris</a> translator glasses it showed off two years ago. Earlier this year, all Google spokesperson Jane Park would tell us was that the glasses were “<a href="https://www.theverge.com/2024/5/14/24156518/google-glass-prototype-ar-glasses-io-2024">a functional research prototype</a>.” </p>
<p id="nbPDvv">Now, they appear to be something at least a little more than that. During a press briefing ahead of the launch of Gemini 2.0, Bibo Xu, a product manager on the Google DeepMind team, said that “a small group will be testing Project Astra on prototype glasses, which we believe is one of the most powerful and intuitive form factors to experience this kind of AI.” That group will be part of Google’s Trusted Tester program, which often gets access to these early prototypes, many of which don’t ever ship publicly. Some testers will use Astra on an Android phone; others through the glasses.</p>
<div id="TGH9Ac"><div style="left: 0; width: 100%; height: 0; position: relative; padding-bottom: 56.25%;"><iframe src="https://www.youtube.com/embed/hIIlJt8JERI?rel=0" style="top: 0; left: 0; width: 100%; height: 100%; position: absolute; border: 0;" allowfullscreen="" scrolling="no" allow="accelerometer; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share;"></iframe></div></div>
<p id="TmdjhB">Later in the briefing, in response to a question about the glasses, Xu said that “for the glasses product itself, we’ll have more news coming shortly.” Is that definitive proof that Google Smart Glasses are coming to a store near you sometime soon? Of course not! But it certainly indicates that Google has some hardware plans for Project Astra.</p>
<p id="N9VhLr">Smart glasses make perfect sense for what Google is trying to do with Astra. There’s simply no better way to combine audio, video, and a display than on a device on your face — especially if you’re hoping for something like an always-on experience. In a new video showing Astra’s capabilities with Gemini 2.0, a tester uses Astra to remember security codes at an apartment building, check the weather, and much more. At one point, he sees a bus flying past and asks Astra if “that bus will take me anywhere near Chinatown.” It’s all the sort of thing you <em>can </em>do with a phone, but nearly all of it feels far more natural through a wearable.</p>
<p id="14be84">Right now, smart glasses like these — and like <a href="https://www.theverge.com/24253908/meta-orion-ar-glasses-demo-mark-zuckerberg-interview">Meta’s Orion</a> — are mostly vaporware. When they’ll ship, <em>whether </em>they’ll ship, and whether they’ll be any good all remains up in the air. But Google is dead serious about making smart glasses work. And seems to be just as serious about making the smart glasses itself.</p>

]]></description><link>https://www.theverge.com/2024/12/11/24318672/google-smart-glasses-ai-gemini</link><guid isPermaLink="true">https://www.theverge.com/2024/12/11/24318672/google-smart-glasses-ai-gemini</guid><dc:creator><![CDATA[David Pierce]]></dc:creator><pubDate>Wed, 11 Dec 2024 15:30:00 GMT</pubDate></item><item><title><![CDATA[Google’s new Jules AI agent will help developers fix buggy code]]></title><description><![CDATA[  

    <figure>
      <img alt="An illustration of Google’s multicolor “G” logo" src="https://cdn.vox-cdn.com/thumbor/wEhfAvC2MonJj2pXsrH-puCX3SU=/0x0:2040x1360/1310x873/cdn.vox-cdn.com/uploads/chorus_image/image/73780369/STK093_Google_01.0.jpg" />
        <figcaption>Illustration: The Verge</figcaption>
    </figure>

  <p id="oGsece">Google has announced an experimental AI-powered code agent called “Jules” that can automatically fix coding errors for developers. <a href="https://developers.googleblog.com/en/the-next-chapter-of-the-gemini-era-for-developers">Jules was introduced today</a> alongside Gemini 2.0, and uses the updated Google AI model to create multi-step plans to address issues, modify multiple files, and prepare pull requests for Python and Javascript coding tasks in GitHub workflows.</p>
<p id="BI4rXb">Microsoft introduced <a href="https://www.theverge.com/2023/3/22/23651456/github-copilot-x-gpt-4-code-chat-voice-support">a similar experience for GitHub Copilot last year</a> that can recognize and explain code, alongside recommending changes and fixing bugs. Jules will compete against Microsoft’s offering, and also against tools like <a href="https://www.cursor.com/">Cursor</a> and even Claude and ChatGPT’s coding abilities. Google’s launch of a coding-focused AI assistant is no surprise — <a href="https://www.theverge.com/2024/10/29/24282757/google-new-code-generated-ai-q3-2024">CEO Sundar Pichai said in October</a> that more than a quarter of all new code at the company is now generated by AI.</p>
<p id="OPzYlw">“Jules handles bug fixes and other time-consuming tasks while you focus on what you actually want to build,” Google says in its blog post. “This effort is part of our long-term goal of building AI agents that are helpful in all domains, including coding.”</p>
<p id="SsLVQy">Developers have full control to review and adjust the plans created by Jules, before choosing to merge the code it generates into their projects. The announcement doesn’t say that Jules will <em>spot </em>bugs for you, so presumably it needs to be directed to a list of issues that have already been identified to fix. Google also says that Jules is in early development and “may make mistakes,” but internal testing has shown it’s been beneficial for boosting developer productivity and providing real-time updates to help track and manage tasks.</p>
<p id="e4WGaG">Jules is launching today for a “select group of trusted testers” according to Google, and will be released to other developers in early 2025. Updates about availability and how development is progressing will be available via the <a href="http://labs.google.com/jules">Google Labs website</a>.</p>

]]></description><link>https://www.theverge.com/2024/12/11/24318628/jules-google-ai-coding-agent-gemini-2-0-announcement</link><guid isPermaLink="true">https://www.theverge.com/2024/12/11/24318628/jules-google-ai-coding-agent-gemini-2-0-announcement</guid><dc:creator><![CDATA[Jess Weatherbed]]></dc:creator><pubDate>Wed, 11 Dec 2024 15:30:00 GMT</pubDate></item><item><title><![CDATA[Google is testing Gemini AI agents that help you in video games]]></title><description><![CDATA[  

    <figure>
      <img alt="Promotional art for Clash of Clans." src="https://cdn.vox-cdn.com/thumbor/cX3NSYMJRchmIymGKsOKgx9ubtQ=/82x0:969x591/1310x873/cdn.vox-cdn.com/uploads/chorus_image/image/73780368/fc_16x9_Super_Wall_Breakers_Even.0.png" />
        <figcaption><em>Clash of Clans.</em> | Image: Supercell</figcaption>
    </figure>

  <p id="29VbeG">Google just announced Gemini 2.0, and as part of its suite of news today, the company is revealing that it’s been exploring how AI agents built with Gemini 2.0 can understand rules in video games to help you out.</p>
<p id="LhYnpp">The agents can “reason about the game based solely on the action on the screen, and offer up suggestions for what to do next in real time conversation,” Google DeepMind CEO Demis Hassabis and CTO Koray Kavukcuoglu write <a href="https://blog.google/technology/google-deepmind/google-gemini-ai-update-december-2024">in a blog post</a>. Hassabis and Kavukcuoglu also say that the agents can also “tap into Google Search to connect you with the wealth of gaming knowledge on the web.”</p>
<p id="RYJRFc">Google is testing the agents’ “ability to interpret rules and challenges” in games like <em>Clash of Clans</em> and <em>Hay Day </em>from Supercell<em>, </em>according to Hassabis and Kavukcuoglu.</p>
<p id="Bdb9uA">I’m not surprised Google is chasing these ideas: in theory, an AI agent coaching you through a strategy or puzzle could be useful. It sounds like this work is very early, though, and I have many questions about whether or not these agents actually give sound advice.</p>
<p id="2Obiyz">Google is also investing in video games and AI in another way: creating playable virtual worlds on the fly from a prompt image using a “foundation world model” called Genie 2 <a href="https://www.theverge.com/2024/12/4/24313409/a-google-ai-model-can-create-playable-virtual-worlds-on-the-fly">that it showed off last week</a>. That work seems early, too: Genie 2 can only generate consistent worlds for “up to a minute,” <a href="https://deepmind.google/discover/blog/genie-2-a-large-scale-foundation-world-model/">Google says</a>.</p>

]]></description><link>https://www.theverge.com/2024/12/11/24318530/google-gemini-2-0-understand-rules-video-games-genie</link><guid isPermaLink="true">https://www.theverge.com/2024/12/11/24318530/google-gemini-2-0-understand-rules-video-games-genie</guid><dc:creator><![CDATA[Jay Peters]]></dc:creator><pubDate>Wed, 11 Dec 2024 15:30:00 GMT</pubDate></item><item><title><![CDATA[Google launched Gemini 2.0, its new AI model for practically everything]]></title><description><![CDATA[  

    <figure>
      <img alt="Vector illustration of the Google Gemini logo." src="https://cdn.vox-cdn.com/thumbor/a-iqXhjLSu3ID3fJsw-0PpvgCuc=/20x0:2021x1334/1310x873/cdn.vox-cdn.com/uploads/chorus_image/image/73780371/STK255_Google_Gemini_C.0.jpg" />
        <figcaption>Illustration: The Verge</figcaption>
    </figure>

  <p id="21tGpz">Google’s latest AI model has a lot of work to do. Like <a href="https://www.theverge.com/23610427/chatbots-chatgpt-new-bing-google-bard-conversational-ai">every other company</a> in the AI race, Google is frantically building AI into practically every product it owns, trying to build products other developers want to use, and racing to set up all the infrastructure to make those things possible without being so expensive it runs the company out of business. Meanwhile, Amazon, Microsoft, Anthropic, and OpenAI are <a href="https://www.theverge.com/24278413/ai-manifesto-anthropic-dario-amodei-agi-digital-god-openai-sam-altman-decoder-podcast">pouring their own billions</a> into pretty much the exact same set of problems. </p>
<p id="v2jVay">That may explain why Demis Hassabis, the CEO of Google DeepMind and the head of all the company’s AI efforts, is so excited about how all-encompassing the new Gemini 2.0 model is. Google <a href="https://blog.google/technology/google-deepmind/google-gemini-ai-update-december-2024">is releasing Gemini 2.0</a> on Wednesday, about 10 months after the company <a href="https://www.theverge.com/2024/2/15/24073457/google-gemini-1-5-ai-model-llm">first launched 1.5</a>. It’s still in what Google calls an “experimental preview,” and only one version of the model — the smaller, lower-end 2.0 Flash — is being released. But Hassabis says it’s still a big day.</p>
<p id="uiE4fp">“Effectively,” Hassabis says, “it’s as good as the current Pro model is. So you can think of it as one whole tier better, for the same cost efficiency and performance efficiency and speed. We’re really happy with that.” And not only is it better at doing the old things Gemini could do but it can also do new things. Gemini 2.0 can now natively generate audio and images, and it brings new multimodal capabilities that Hassabis says lay the groundwork for the next big thing in AI: agents.</p>
<p id="ZOObHN">Agentic AI, as everyone calls it, refers to AI bots that can actually go off and accomplish things on your behalf. Google has been demoing one, Project Astra, <a href="https://www.theverge.com/2024/5/14/24156296/google-ai-gemini-astra-assistant-live-io">since this spring</a> — it’s a visual system that can identify objects, help you navigate the world, and tell you where you left your glasses. Gemini 2.0 represents a huge improvement for Astra, Hassabis says. </p>
<p id="R9r4Fo">Google is <a href="https://www.theverge.com/2024/12/11/24317436/google-deepmind-project-astra-mariner-ai-agent">also launching Project Mariner</a>, an experimental new Chrome extension that can quite literally use your web browser for you. There’s also <a href="https://www.theverge.com/2024/12/11/24318628/jules-google-ai-coding-agent-gemini-2-0-announcement">Jules</a>, an agent specifically for helping developers find and fix bad code, and a new Gemini 2.0-based agent that can look at your screen and help you <a href="https://www.theverge.com/2024/12/11/24318530/google-gemini-2-0-understand-rules-video-games-genie">better play video games</a>. Hassabis calls the game agent “an Easter egg” but also points to it as the sort of thing a truly multimodal, built-in model can do for you.</p>
<p id="GGqWR1">“We really see 2025 as the true start of the agent-based era,” Hassabis says, “and Gemini 2.0 is the foundation of that.” He’s careful to note that the performance isn’t the only upgrade here; as talk of an industrywide slowdown in model improvements continues, he says Google is still seeing gains as it trains new models, but he’s just as excited about the efficiency and speed improvements. </p>
<div class="c-float-left c-float-hang"><aside id="PM1JyZ"><q>Google’s plan for Gemini 2.0 is to use it absolutely everywhere</q></aside></div>
<p id="1GqEN4">This won’t shock you, but Google’s plan for Gemini 2.0 is to use it absolutely everywhere. It will power AI Overviews in Google Search, which Google says now reach 1 billion people and which the company says will now be more nuanced and complex thanks to Gemini 2.0. It’ll be in the Gemini bot and app, of course, and will eventually power the AI features in Workspace and elsewhere at Google. Google has worked to bring as many features as possible into the model itself, rather than run a bunch of individual and siloed products, in order to be able to do more with Gemini in more places. The multimodality, the different kinds of outputs, the features — the goal is to get all of it into the foundational Gemini model. “We’re trying to build the most general model possible,” Hassabis says. </p>
<p id="LUeaBs">As the agentic era of AI begins, Hassabis says there are both new and old problems to solve. The old ones are eternal, about performance and efficiency and inference cost. The new ones are in many ways unknown. Just to name one: what safety risks will these agents pose out in the world operating of their own accord? Google is taking some precautions with Mariner and Astra, but Hassabis says there’s more research to be done. “We’re going to need new safety solutions,” he says, “like testing in hardened sandboxes. I think that’s going to be quite important for testing agents, rather than out in the wild… they’ll be more useful, but there will also be more risks.”</p>
<p id="nlPQPN">Gemini 2.0 may be in an experimental stage for now, but you can already use it by choosing the new model in the Gemini web app. (No word yet on when you’ll get to try the non-Flash models.) And early next year, Hassabis says, it’s coming for other Gemini platforms, everything else Google makes, and the whole internet.</p>
<p id="oU44Sk"></p>
<p id="pwLFQ3"></p>

]]></description><link>https://www.theverge.com/2024/12/11/24318444/google-gemini-2-0-flash-ai-model</link><guid isPermaLink="true">https://www.theverge.com/2024/12/11/24318444/google-gemini-2-0-flash-ai-model</guid><dc:creator><![CDATA[David Pierce]]></dc:creator><pubDate>Wed, 11 Dec 2024 15:30:00 GMT</pubDate></item><item><title><![CDATA[Google built an AI tool that can do research for you]]></title><description><![CDATA[  

    <figure>
      <img alt="Image of the Google “G” logo on a blue, black, and purple background." src="https://cdn.vox-cdn.com/thumbor/g5HvsCeZn9sMSwV_9yDzL_PqR_M=/0x0:2040x1360/1310x873/cdn.vox-cdn.com/uploads/chorus_image/image/73780370/STK093_Google_03.0.jpg" />
        <figcaption>Illustration: The Verge</figcaption>
    </figure>

  <p id="pKZYbR">Google has just revealed a new AI tool <a href="http://hps://blog.google/products/gemini/google-gemini-deep-research/">called Deep Research</a> that lets you call upon its Gemini bot to scour the web for you and write a detailed report based on its findings.</p>
<p id="OOYdiW">Deep Research is currently only available in English to Gemini Advanced subscribers. If you have access, you can ask Gemini to research a particular topic on your behalf, and the chatbot will create a “multi-step research plan” that you can either edit or approve. Google says Gemini will start its research by “finding interesting pieces of information” on the web and then performing related searches — a process it repeats several times.</p>
<figure class="e-image">
        <img alt=" " data-mask-text="false" src="https://cdn.vox-cdn.com/thumbor/FXcThBc2tlONIRUrL2jsd_6xEJo=/400x0/filters:no_upscale()/cdn.vox-cdn.com/uploads/chorus_asset/file/25784204/deep_research.gif">
      <cite>GIF: Google</cite>
  </figure>
<div class="c-float-left c-float-hang"><aside id="UjZrEc"><div data-anthem-component="readmore" data-anthem-component-data='{"stories":[{"title":"Agents are the future AI companies promise — and desperately need","url":"https://www.theverge.com/2024/10/10/24266333/ai-agents-assistants-openai-google-deepmind-bots"}]}'></div></aside></div>
<p id="oFi60y">When it’s finished, Gemini will spit out a report of its “key findings” with links to the websites where it found its information. You can ask Gemini to expand on certain areas or tweak its report, as well as export the AI-generated research to Google Docs. This all sounds a bit similar to the <a href="https://www.theverge.com/2024/5/30/24167986/perplexity-ai-research-pages-school-report">Pages feature offered by the AI search engine Perplexity</a>, which generates a custom webpage based on your prompt.</p>
<p id="WkVYdb">Google took the wraps off Deep Research as part of a broader announcement for Gemini 2.0, its new model for an era of “agentic” AI, or the AI systems that can perform tasks for you. Deep Research is just one example of Google’s agentic push, and it’s <a href="https://www.theverge.com/2024/10/10/24266333/ai-agents-assistants-openai-google-deepmind-bots">something other AI companies</a> are seriously exploring as well.</p>
<p id="N43w9r">Along with Deep Research, Google announced that it’s making Gemini Flash 2.0 — <a href="https://www.theverge.com/2024/7/25/24206071/google-gemini-ai-flash-upgrade">a speedier version of the next-gen chatbot</a> — available to developers. Deep Research is currently only available for Gemini Advanced subscribers on the web. You can try it by heading to Gemini and then changing the model dropdown to “Gemini 1.5 Pro with Deep Research.” </p>

]]></description><link>https://www.theverge.com/2024/12/11/24318217/google-gemini-advanced-deep-research-launch</link><guid isPermaLink="true">https://www.theverge.com/2024/12/11/24318217/google-gemini-advanced-deep-research-launch</guid><dc:creator><![CDATA[Emma Roth]]></dc:creator><pubDate>Wed, 11 Dec 2024 15:30:00 GMT</pubDate></item><item><title><![CDATA[Video app Kino, from maker of Halide, is Apple’s iPhone app of the year]]></title><description><![CDATA[<p>ChatGPT may currently be the No. 1 app on the iPhone App Store in the U.S., but it&#8217;s not Apple&#8217;s iPhone app of the year. That honor instead goes to a newer app for videographers, Kino. Launched this spring from Lux, the company behind the professional photography app, Halide, Kino advances mobile video recording with [&#8230;]</p>
<p>© 2024 TechCrunch. All rights reserved. For personal use only.</p>
]]></description><link>https://techcrunch.com/2024/12/11/video-app-kino-from-maker-of-halide-is-apples-iphone-app-of-the-year/</link><guid isPermaLink="true">https://techcrunch.com/2024/12/11/video-app-kino-from-maker-of-halide-is-apples-iphone-app-of-the-year/</guid><pubDate>Wed, 11 Dec 2024 15:41:10 GMT</pubDate></item><item><title><![CDATA[Gemini 2.0, Google’s newest flagship AI, can generate text, images, and speech]]></title><description><![CDATA[<p>Google&#8217;s next major AI model has arrived to combat a slew of new offerings from OpenAI. On Wednesday, Google announced Gemini 2.0 Flash, which the company says can natively generate images and audio in addition to text. 2.0 Flash can also use third-party apps and services, allowing it to tap into Google Search, execute code, [&#8230;]</p>
<p>© 2024 TechCrunch. All rights reserved. For personal use only.</p>
]]></description><link>https://techcrunch.com/2024/12/11/gemini-2-0-googles-newest-flagship-ai-can-generate-text-images-and-speech/</link><guid isPermaLink="true">https://techcrunch.com/2024/12/11/gemini-2-0-googles-newest-flagship-ai-can-generate-text-images-and-speech/</guid><pubDate>Wed, 11 Dec 2024 15:30:00 GMT</pubDate></item><item><title><![CDATA[Google unveils Project Mariner: AI agents to use the web for you]]></title><description><![CDATA[<p>Google unveiled its first-ever AI agent that can take actions on the web on Wednesday, a research prototype from the company&#8217;s DeepMind division called Project Mariner. The Gemini-powered agent takes control of your Chrome browser, moves the cursor on your screen, clicks buttons, and fills out forms, allowing it to use and navigate websites much [&#8230;]</p>
<p>© 2024 TechCrunch. All rights reserved. For personal use only.</p>
]]></description><link>https://techcrunch.com/2024/12/11/google-unveils-project-mariner-ai-agents-to-use-the-web-for-you/</link><guid isPermaLink="true">https://techcrunch.com/2024/12/11/google-unveils-project-mariner-ai-agents-to-use-the-web-for-you/</guid><pubDate>Wed, 11 Dec 2024 15:30:00 GMT</pubDate></item><item><title><![CDATA[Google’s AI Overviews will soon be able to answer math and coding questions]]></title><description><![CDATA[<p>Google's AI Overviews feature on Search is getting an upgrade, thanks to the company's newly launched Gemini 2.0 model.</p>
<p>© 2024 TechCrunch. All rights reserved. For personal use only.</p>
]]></description><link>https://techcrunch.com/2024/12/11/googles-ai-overviews-will-soon-answer-math-and-coding-questions/</link><guid isPermaLink="true">https://techcrunch.com/2024/12/11/googles-ai-overviews-will-soon-answer-math-and-coding-questions/</guid><pubDate>Wed, 11 Dec 2024 15:30:00 GMT</pubDate></item><item><title><![CDATA[Google Gemini can now do more in-depth research]]></title><description><![CDATA[<p>Google is bringing a new capability to Gemini, its chatbot platform, that enables the AI to perform 'deep research' on a subject.</p>
<p>© 2024 TechCrunch. All rights reserved. For personal use only.</p>
]]></description><link>https://techcrunch.com/2024/12/11/gemini-can-now-research-deeper/</link><guid isPermaLink="true">https://techcrunch.com/2024/12/11/gemini-can-now-research-deeper/</guid><pubDate>Wed, 11 Dec 2024 15:30:00 GMT</pubDate></item><item><title><![CDATA[Google parent Alphabet jumps on quantum chip breakthrough - Reuters]]></title><description><![CDATA[<ol><li><a href="https://news.google.com/rss/articles/CBMiowFBVV95cUxOSGtQRmI2TEJ4Q19fMlprV2dNcFF0VXY0dVBvV1Y2aS1vZF9nT2x3RTZWaktsU1E1MnB6UzVFWjM3R1R6T3FCOU9XclpENlp5dkJnRDg2TGMtRXBic1JCSXdEMnYzdzgwUEpyTXRINU9jeFBoY0JUNUU0a29kMzktamFYcXF6dW1Xb3B5YmhoOGczekkzY3RSOXZ4cHFKMzAyTzlZ?oc=5" target="_blank">Google parent Alphabet jumps on quantum chip breakthrough</a>&nbsp;&nbsp;<font color="#6f6f6f">Reuters</font></li><li><a href="https://news.google.com/rss/articles/CBMidkFVX3lxTE9TYU9sQjg4VjNLMjVEY2VweEQ1eHZ0UnBFbFNUcmttZnU1YjVXVlBzSFRhQURiMXRuNXhFTmNDTnUzUlBxaGxNVG5pUGEybzBfOTBUMVVPeEJITzNiTFBvV2dSZExodlBaT0I4SEQzUUlUXzFjZWc?oc=5" target="_blank">Meet Willow, our state-of-the-art quantum chip</a>&nbsp;&nbsp;<font color="#6f6f6f">The Keyword</font></li><li><a href="https://news.google.com/rss/articles/CBMigAFBVV95cUxPS0FRcW9qa3VXb3ZGaGZXMHdrLURCekhKdlVMSWFLb21MTkdHZVQzVEo0Z3BMTlRQbWpleklLcy1XSzZyZ29EbGZnNWw2Q0RtWjNXWTVRcmQyc2hYRGY0WURQbVJNNFFhZzM2bFExYU1CeWhfMDlZYkRmS3pRd3BiMA?oc=5" target="_blank">Google Makes New Quantum Computing Breakthrough</a>&nbsp;&nbsp;<font color="#6f6f6f">The New York Times</font></li><li><a href="https://news.google.com/rss/articles/CBMisgFBVV95cUxOVG9sYzNEc1gyVkx0OUdiVHQyTEE3TUVFOEhtc2VNbTU0d3pSb0tXcWdEaXJQSVFoMTlUV0RMZmg2a3otaTFXNGhKeGxSODVvaVJwUXFtN0lrTGx2TWtpc0dIOHA5WC1WUWRTcmxoeVlubjY4NVM3aW1oeFc1MEFxR3lzcThpOXQwdWlxMmktS182dVBYNWptWlFBQVM2MTYtNWtwcDY2cEFTTW1idDBOMVJR?oc=5" target="_blank">Google Flexes Its Tech Muscles With Quantum Computing Chip, Waymo</a>&nbsp;&nbsp;<font color="#6f6f6f">Investor's Business Daily</font></li><li><a href="https://news.google.com/rss/articles/CBMitAFBVV95cUxPbTA3WjVxQS1ZSS1KN1o4Sk5aN3BLeE9vY0I1UWZNZEc2ZWdxVWtldDRLaVJMZGg2amlVZklxVFplaUpxSGt3WTN5SHZ3QWRhR3BuTXd2M1g0ZENabkhqUERPOU9KVlNjLUVoOG9fWV81ZWRnMWpNd3gxSGdOVmF1UjFmUldoYXhJUnBzY0RWdm90NGRXRm5uMjdwRnRXM0xoYnk2c2ltVTNjSUZaNFlERktFMmE?oc=5" target="_blank">Alphabet Climbs After Breakthrough With Willow Quantum Chip</a>&nbsp;&nbsp;<font color="#6f6f6f">Bloomberg</font></li></ol>]]></description><link>https://news.google.com/rss/articles/CBMiowFBVV95cUxOSGtQRmI2TEJ4Q19fMlprV2dNcFF0VXY0dVBvV1Y2aS1vZF9nT2x3RTZWaktsU1E1MnB6UzVFWjM3R1R6T3FCOU9XclpENlp5dkJnRDg2TGMtRXBic1JCSXdEMnYzdzgwUEpyTXRINU9jeFBoY0JUNUU0a29kMzktamFYcXF6dW1Xb3B5YmhoOGczekkzY3RSOXZ4cHFKMzAyTzlZ?oc=5</link><guid isPermaLink="true">https://news.google.com/rss/articles/CBMiowFBVV95cUxOSGtQRmI2TEJ4Q19fMlprV2dNcFF0VXY0dVBvV1Y2aS1vZF9nT2x3RTZWaktsU1E1MnB6UzVFWjM3R1R6T3FCOU9XclpENlp5dkJnRDg2TGMtRXBic1JCSXdEMnYzdzgwUEpyTXRINU9jeFBoY0JUNUU0a29kMzktamFYcXF6dW1Xb3B5YmhoOGczekkzY3RSOXZ4cHFKMzAyTzlZ?oc=5</guid><pubDate>Wed, 11 Dec 2024 02:24:00 GMT</pubDate></item><item><title><![CDATA[iOS 18.2 is rolling out today, adding ChatGPT integration and more Apple Intelligence tools - The Verge]]></title><description><![CDATA[<ol><li><a href="https://news.google.com/rss/articles/CBMikgFBVV95cUxNTThxX2xkYkdHRXhnLU5tdV9ZWWlYYUVzYmR3a0lXbm1weWVuNFlreUdWREpmQjg4QndtUm9RVlpDTkxzTGRXZ2hYcFJaTmQ4ZEtTdFNhM2k5WkFnSWo0N0pRdzBGcjJoRXVCZEpBMWRwU21yNms4MEdGU3dUQTBYRW81YXdRa0hINWNPNTd3aHJCQQ?oc=5" target="_blank">iOS 18.2 is rolling out today, adding ChatGPT integration and more Apple Intelligence tools</a>&nbsp;&nbsp;<font color="#6f6f6f">The Verge</font></li><li><a href="https://news.google.com/rss/articles/CBMijAFBVV95cUxPbnRhWlpNLWw4M3JfZi1IQ05MaGhCeXBSamVMekxhUWlrVEhNU3ZCOUVCUmNPTXM0VXg4RzBHakJIbXJvakhfcHdtaFE3R2FaRHE3bFlyTC15S0ZaWXZDNG5Tb2s2RkpWRUhtaWlXLUs3SEE2c2dPa0lkMkRRODN4LUxjTTRwcDBxTTRrSQ?oc=5" target="_blank">iOS 18.2 Review: The AI Apple Promised Us</a>&nbsp;&nbsp;<font color="#6f6f6f">The Wall Street Journal</font></li><li><a href="https://news.google.com/rss/articles/CBMiwAFBVV95cUxOS3BFVXhhUl9zN051Nm1tVjd3U1ZuZWV2RWRfeks5YUFHMUdvYzh4cXphTTNWNE5GcDNIbmxmZUF4aWJ0WVNpZ01XR1hIQkJaVXhnVFAwckZ0djRCMjZwaHhuRGR2TmRudDE0a1QzRjZlR1NabUEtbmsxTnVEU194bGhjNkV5d0dEV1pPR1dLdHJPMVFoOXU0d3NLRnplR3V1SFVJNXpKNFJUNWhjQkNhS0lpakUzQ3VHUi03UG0tOTA?oc=5" target="_blank">Apple brings more Apple Intelligence features to iPhones, iPads, Macs</a>&nbsp;&nbsp;<font color="#6f6f6f">Deccan Herald</font></li><li><a href="https://news.google.com/rss/articles/CBMisAFBVV95cUxOWDc2Yml6Smg0bmFRemRlTlA4RFVxSFdjQjVlRWdmWUFTLV80WmVYTzdZT0JOT3JBM0FzTlRNZ2g0R1ZfRmRVZ01FRUVXVmpuQkJYemo3eWFDanp0WUtKUFAtTVhkeTNYVXNuSUZld1VPVWo5OGFaak1iMk1TWkU3Y24xUmxfV2VZSmJCRzZKTXJ1eWd5MzdjaGVLVFJXV1JMMGNpYkNnaDNmUDBlWmNHUw?oc=5" target="_blank">Apple’s Surprising iPhone Update—Green Bubbles End This Week</a>&nbsp;&nbsp;<font color="#6f6f6f">Forbes</font></li><li><a href="https://news.google.com/rss/articles/CBMijgFBVV95cUxNd2wydUs4dDJWR2syVkVQT2k2Sk8tR19CaF9tVlhHWUR3UHJReEFwa1ExQ0RfMlZJekJkbVl6THhfWjc3WTUyak01WDVndTNWNUhNemhFWkNJVWppNVVjVWlqMkJwSml6aGU4X2NSajFnLTZkTUp3aHFBN2RKeS1nbmlXbFFsR1VWMFRwUVRB0gGTAUFVX3lxTE9mVE1DQ1lkZF9JRm5ORjFvSUhnOVZNWmVEQlR2ZUVrVlFQVFRKNnVWMUZndS0yUDhJQzVsMU5NSzh1QWtWelhxbDI1Z28zWmdaem5MMWp0SjNaanJPSHQ5VVVZY0d3Yi1lTHhjb0VreUhPbU5mUEdLbFRFcUJSbGNXTTUzTTJZTElSTy1MdzRMNkp2SQ?oc=5" target="_blank">Apple launches its ChatGPT integration with Siri</a>&nbsp;&nbsp;<font color="#6f6f6f">CNBC</font></li></ol>]]></description><link>https://news.google.com/rss/articles/CBMikgFBVV95cUxNTThxX2xkYkdHRXhnLU5tdV9ZWWlYYUVzYmR3a0lXbm1weWVuNFlreUdWREpmQjg4QndtUm9RVlpDTkxzTGRXZ2hYcFJaTmQ4ZEtTdFNhM2k5WkFnSWo0N0pRdzBGcjJoRXVCZEpBMWRwU21yNms4MEdGU3dUQTBYRW81YXdRa0hINWNPNTd3aHJCQQ?oc=5</link><guid isPermaLink="true">https://news.google.com/rss/articles/CBMikgFBVV95cUxNTThxX2xkYkdHRXhnLU5tdV9ZWWlYYUVzYmR3a0lXbm1weWVuNFlreUdWREpmQjg4QndtUm9RVlpDTkxzTGRXZ2hYcFJaTmQ4ZEtTdFNhM2k5WkFnSWo0N0pRdzBGcjJoRXVCZEpBMWRwU21yNms4MEdGU3dUQTBYRW81YXdRa0hINWNPNTd3aHJCQQ?oc=5</guid><pubDate>Wed, 11 Dec 2024 13:10:36 GMT</pubDate></item><item><title><![CDATA[Apple honors 2024 App Store Award winners - Apple Newsroom]]></title><description><![CDATA[<ol><li><a href="https://news.google.com/rss/articles/CBMiiAFBVV95cUxNRi04MXFIdHlSQTFFWW5abUEyU3pteW5vZVE0NGhodnZBZ0NpaHllOElDWUg4bFZOZDlUN3EwRGc3bDZTU1BabVBYRnAzLVhLSDdNTEluRHIweGJDVDBLZVZOOGVMZWtxaTY0YUZ1elNBb0NHLVEzN2t6QVlXRndfUGhOOXEtOWdC?oc=5" target="_blank">Apple honors 2024 App Store Award winners</a>&nbsp;&nbsp;<font color="#6f6f6f">Apple Newsroom</font></li><li><a href="https://news.google.com/rss/articles/CBMisgFBVV95cUxQVXViWE1xT09qZEo3STdvR3NwVEhVaktLakdsMWVKd0xOSTBhODhGMjFPY0M2WHY0YUZWZjRvRHNvRE54akgtQWt0dVRCLUNYWGFodzZRWTloano0REVuQmJlakM0THNyUnpwSzhuSXE2ZTdOcFoybHNpeUJrSDNwM3R2T2l4QUp0RWNkRklucjdSRm9NbXJIZHlwS0lGTDdJbGRFcHJwY19aQ3ZEUDBCb1ln?oc=5" target="_blank">Balatro+ is Apple's Arcade Game of the Year because of course it is</a>&nbsp;&nbsp;<font color="#6f6f6f">Engadget</font></li><li><a href="https://news.google.com/rss/articles/CBMibkFVX3lxTFBKYnNQSXRMejhNX2lhZnhvVG5BdGw1TWhlYUpwZjlMX1lIZEN6ellpN2Vtekp2LVJFMHJOb0YzVWhXZ2c4WUhDellGSGxCWG9GREZibGVrMy1qdU41Mm1VM3E2RUZEX2pVYTlFNDZ3?oc=5" target="_blank">Here are the winners of the 2024 App Store Awards</a>&nbsp;&nbsp;<font color="#6f6f6f">9to5Mac</font></li><li><a href="https://news.google.com/rss/articles/CBMiowFBVV95cUxPaEhkd0tibEtZeXZHUV8yMEV4SkowOVFDNmpETmpRM2FMVXB5NlJnSmhEeldSYmkzQVZVOVVockFvalc3V3VQWHZLeFZPSlFsbG5pUVZUcXFxQkNwcTNZYkdIbW41YjlkVkpoVGJtYnJ2Yl9vbjdUSzF6ZHozOVR4eDVzUVlzNXkzbTNLbWk0RUx2Slo5X2NmM2V0WVhWSzhDaWpJ?oc=5" target="_blank">Kino and Adobe Lightroom Honored Among Apple’s 2024 Apps of the Year</a>&nbsp;&nbsp;<font color="#6f6f6f">PetaPixel</font></li><li><a href="https://news.google.com/rss/articles/CBMif0FVX3lxTE1BeGo3NVhGVmJVUFFONlJLa2Q5dko3UVlkMTZuN2dGemlGWUd5Z0ZtT244R0xNOGRMeERLS3F4UkRJVm1wdU1nclN0Rm1ZeEc0QWJTMHNlM1dLQUtGalVobEhCanJGWGFvT2lPSGVXTUFrOXdDaW1lLXNXMXhaNDDSAYQBQVVfeXFMT1lWVENyM3NmemJfSXhnM1BjRDN1bzZFZ1hGb3dOLTYzQ2djMV93dG5HbEVtSFdNMmxKSWlUVGt2SVZ4MVRneHdEMktoVXZmbWlKSm8wSTlZemJhVjNHRDRqejA0cUNNck94dkRhdS1MajZmYVh5bXVrc0pvcThhVWxtMXow?oc=5" target="_blank">‘Balatro’ highlights Apple announces App Store Award winners</a>&nbsp;&nbsp;<font color="#6f6f6f">The Mercury News</font></li></ol>]]></description><link>https://news.google.com/rss/articles/CBMiiAFBVV95cUxNRi04MXFIdHlSQTFFWW5abUEyU3pteW5vZVE0NGhodnZBZ0NpaHllOElDWUg4bFZOZDlUN3EwRGc3bDZTU1BabVBYRnAzLVhLSDdNTEluRHIweGJDVDBLZVZOOGVMZWtxaTY0YUZ1elNBb0NHLVEzN2t6QVlXRndfUGhOOXEtOWdC?oc=5</link><guid isPermaLink="true">https://news.google.com/rss/articles/CBMiiAFBVV95cUxNRi04MXFIdHlSQTFFWW5abUEyU3pteW5vZVE0NGhodnZBZ0NpaHllOElDWUg4bFZOZDlUN3EwRGc3bDZTU1BabVBYRnAzLVhLSDdNTEluRHIweGJDVDBLZVZOOGVMZWtxaTY0YUZ1elNBb0NHLVEzN2t6QVlXRndfUGhOOXEtOWdC?oc=5</guid><pubDate>Wed, 11 Dec 2024 14:02:15 GMT</pubDate></item><item><title><![CDATA[Is Rigetti Computing, Inc. (RGTI) the Best Quantum Computing Stock to Buy According to Hedge Funds?]]></title><link>https://finance.yahoo.com/news/rigetti-computing-inc-rgti-best-061830360.html</link><guid isPermaLink="true">https://finance.yahoo.com/news/rigetti-computing-inc-rgti-best-061830360.html</guid><pubDate>Wed, 11 Dec 2024 06:18:30 GMT</pubDate></item></channel></rss>